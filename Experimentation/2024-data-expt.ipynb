{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "sys.path.append('/home/k64835/Master-Thesis-SITS')\n",
    "\n",
    "scripts_path = Path(\"../Data-Preprocessing/\").resolve()\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "scripts_path = Path(\"../Evaluation/\").resolve()\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "scripts_path = Path(\"../Modeling/\").resolve()\n",
    "sys.path.append(str(scripts_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from scripts.data_visualiser import *\n",
    "from sklearn.manifold import TSNE \n",
    "from model_scripts.feature_extraction import *\n",
    "from model_scripts.executions import *\n",
    "import torch.nn.functional as F\n",
    "from Experimentation.expt_scripts.sugarcontent_data_processing import *\n",
    "from Experimentation.expt_scripts.expt_plots import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model_scripts.subpatch_extraction import *\n",
    "from Experimentation.expt_scripts.regression import *\n",
    "from scripts.data_loader import *\n",
    "from scripts.data_preprocessor import *\n",
    "from scripts.temporal_data_preprocessor import *\n",
    "from scripts.temporal_data_loader import *\n",
    "from scripts.temporal_visualiser import *\n",
    "from scripts.temporal_chanel_refinement import *\n",
    "from model_scripts.model_helper import *\n",
    "from model_scripts.dataset_creation import *\n",
    "from model_scripts.train_model_ae import *\n",
    "from model_scripts.model_visualiser import *\n",
    "from model_scripts.clustering import *\n",
    "from evaluation_scripts.evaluation_helper import *\n",
    "from evaluation_scripts.result_visualiser import *\n",
    "from Pipeline.temporal_preprocessing_pipeline import *\n",
    "from evaluation_scripts.result_visualiser import *\n",
    "from Pipeline.temporal_preprocessing_pipeline import *\n",
    "import numpy as np\n",
    "import config as config\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import skimage.measure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Prep: B10 for Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Data: Extracted and Pre-processed Patches (each patch containing a sugarbeet field)\n",
    "Dimensions: (N, T, C, H, W) = (N, 7, 10, 64, 64)\n",
    "\n",
    "Here only the train data is used, since we have sugarcontent ground truths only for the train set. We divide this data into train and test again for calculating RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1491, 4, 10, 64, 64]), torch.Size([33, 4, 10, 64, 64]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline = PreProcessingPipelineTemporal()\n",
    "field_numbers_train, acquisition_dates_train, patch_tensor_train, visualisation_train = preprocessing_pipeline.get_processed_temporal_cubes('train', 'b10')\n",
    "field_numbers_eval, acquisition_dates_eval, patch_tensor_eval, visualisation_eval = preprocessing_pipeline.get_processed_temporal_cubes('eval', 'b10')\n",
    "patch_tensor_train.shape, patch_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sub-Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50529, 4, 10, 4, 4]), torch.Size([1213, 4, 10, 4, 4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subpatches, train_subpatch_coords = non_overlapping_sliding_window(patch_tensor_train, field_numbers_train, patch_size=config.subpatch_size)\n",
    "eval_subpatches, eval_subpatch_coords = non_overlapping_sliding_window(patch_tensor_eval, field_numbers_eval, patch_size=config.subpatch_size)\n",
    "train_subpatches.shape, eval_subpatches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get properly formatted field numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1615767.0_12_20'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_coord_fn = get_string_fielddata(train_subpatch_coords)\n",
    "eval_coord_fn = get_string_fielddata(eval_subpatch_coords)\n",
    "eval_coord_fn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-means flattened Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment the below line when loading saved model\n",
    "kmeans = kmeans_function(train_subpatches, n_clusters=2, random_state=101)    \n",
    "\n",
    "train_subpatch_predictions = kmeans.predict(train_subpatches.reshape(train_subpatches.size(0), -1).numpy())\n",
    "eval_subpatch_predictions = kmeans.predict(eval_subpatches.reshape(eval_subpatches.size(0), -1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int32), array([1022,  191]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(eval_subpatch_predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Accuracy: Convert sub-patch level labels to patch-level labels and compare with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease cluster: 0\n",
      "Accuracy: 85.0\n",
      "Precision: 87.18\n",
      "Recall: 97.14\n",
      "F1-score: 91.89\n",
      "F2-score: 94.97\n"
     ]
    }
   ],
   "source": [
    "# disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics(eval_coord_fn, eval_subpatch_predictions, config.labels_path, config.subpatch_to_patch_threshold, 'Flattened Data', True) #for saving predictions\n",
    "disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics(eval_coord_fn, eval_subpatch_predictions, config.labels_path, config.subpatch_to_patch_threshold)\n",
    "print(\"Disease cluster:\", disease)\n",
    "print(\"Accuracy:\",acc)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1-score:\",f1_score)\n",
    "print(\"F2-score:\", f2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Histogram Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50529, 30), (1213, 30))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogram_features_train = extract_global_histogram(train_subpatches, bins=30)\n",
    "histogram_features_eval = extract_global_histogram(eval_subpatches, bins=30)\n",
    "histogram_features_train.shape, histogram_features_eval.shape # (N, T * C * bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment the below line when loading saved model\n",
    "kmeans_hist = kmeans_function(histogram_features_train, n_clusters=2, random_state=102)\n",
    "\n",
    "train_subpatch_predictions = kmeans_hist.predict(histogram_features_train.reshape(histogram_features_train.shape[0],-1))\n",
    "eval_subpatch_predictions = kmeans_hist.predict(histogram_features_eval.reshape(histogram_features_eval.shape[0],-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Accuracy: Convert sub-patch level labels to patch-level labels and compare with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease cluster: 1\n",
      "Accuracy: 85.0\n",
      "Precision: 87.18\n",
      "Recall: 97.14\n",
      "F1-score: 91.89\n",
      "F2-score: 94.97\n"
     ]
    }
   ],
   "source": [
    "# disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics(eval_coord_fn, eval_subpatch_predictions, config.labels_path, config.subpatch_to_patch_threshold, 'Flattened Data', True) #for saving predictions\n",
    "disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics(eval_coord_fn, eval_subpatch_predictions, config.labels_path, config.subpatch_to_patch_threshold)\n",
    "print(\"Disease cluster:\", disease)\n",
    "print(\"Accuracy:\",acc)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1-score:\",f1_score)\n",
    "print(\"F2-score:\", f2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int32), array([1013,  200]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(eval_subpatch_predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conv2D Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DAutoencoder(nn.Module):\n",
    "    def __init__(self, in_channels, time_steps, latent_size, patch_size):\n",
    "        super(Conv2DAutoencoder, self).__init__()\n",
    "\n",
    "        self.time_steps = time_steps\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        # --- Encoder (2D Convolutions, treating time steps as channels) ---\n",
    "        self.conv1 = nn.Conv2d(in_channels * time_steps, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # --- Fully Connected Latent Space ---\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * patch_size * patch_size, 512)\n",
    "        self.fc2 = nn.Linear(512, latent_size)\n",
    "\n",
    "        # --- Decoder (Fully Connected) ---\n",
    "        self.fc3 = nn.Linear(latent_size, 512)\n",
    "        self.fc4 = nn.Linear(512, 256 * patch_size * patch_size)\n",
    "\n",
    "        # --- 2D Deconvolutions ---\n",
    "        self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(64, in_channels * time_steps, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # --- Encoder ---\n",
    "        b, c, t, h, w = x.shape\n",
    "        x = x.reshape(b, c * t, h, w)      # Imp: Time steps as additional channels (B, C * D, H, W)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        # --- Flatten and Fully Connected ---\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        z = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # --- Decoder ---\n",
    "        x = F.relu(self.fc3(z))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        # --- 2D Deconvolutions ---\n",
    "        x = x.view(b, 256, h, w)        \n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = self.deconv3(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        # --- Reshape to B x C x D x H x W ---\n",
    "        x_reconstructed = x.view(b, self.in_channels, self.time_steps, h, w) \n",
    "\n",
    "        return z, x_reconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader for Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subpatches_dl, test_subpatches, train_field_numbers, test_field_numbers = train_test_split(\n",
    "    train_subpatches, train_coord_fn, test_size=1-config.ae_train_test_ratio, random_state=42\n",
    ")\n",
    "\n",
    "dataloader_train = create_data_loader(train_subpatches_dl, train_field_numbers, batch_size=config.ae_batch_size, shuffle=True)\n",
    "dataloader_test = create_data_loader(test_subpatches, test_field_numbers, batch_size=config.ae_batch_size, shuffle=False)\n",
    "dataloader_eval = create_data_loader(eval_subpatches, eval_coord_fn, batch_size=config.ae_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Models and Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2DAutoencoder(\n",
       "  (conv1): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=4096, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  (deconv1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (deconv3): ConvTranspose2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "epochs = 50\n",
    "lr = 0.01\n",
    "latent_dim=32\n",
    "channels = 10\n",
    "optimizer = 'SGD'\n",
    "momentum = 0.9\n",
    "time_steps = config.temporal_stack_size_2024\n",
    "patch_size = config.subpatch_size\n",
    "\n",
    "model = Conv2DAutoencoder(channels, time_steps, latent_dim, patch_size)\n",
    "device = torch.device(device)  \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, train_losses, test_losses = train_model_ae(model, dataloader_train, dataloader_test, epochs=epochs, optimizer=optimizer, lr=lr, momentum=momentum, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_coord_dl = extract_features_ae(trained_model, dataloader_train, temp_embed_pixel=False, device=device)\n",
    "test_features, test_coord_dl = extract_features_ae(trained_model, dataloader_test, temp_embed_pixel=False, device=device)\n",
    "eval_features, eval_coord_dl = extract_features_ae(trained_model, dataloader_eval, temp_embed_pixel=False, device=device)\n",
    "\n",
    "train_features = train_features.cpu()\n",
    "test_features = test_features.cpu()\n",
    "eval_features = eval_features.cpu()\n",
    "\n",
    "combined_train_features = torch.cat((train_features, test_features), dim=0)\n",
    "combined_train_coords = train_coord_dl + test_coord_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means on extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = kmeans_function(combined_train_features, n_clusters=2, random_state=103)    # Skip this when loading saved model\n",
    "\n",
    "train_subpatch_predictions = kmeans.predict(combined_train_features.reshape(combined_train_features.size(0), -1).numpy().astype(np.float32))\n",
    "eval_subpatch_predictions = kmeans.predict(eval_features.reshape(eval_features.size(0), -1).numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int32), array([1004,  209]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(eval_subpatch_predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease cluster: 0\n",
      "Accuracy: 77.5\n",
      "Precision: 86.11\n",
      "Recall: 88.57\n",
      "F1-score: 87.32\n",
      "F2-score: 88.07\n"
     ]
    }
   ],
   "source": [
    "# disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics(eval_coord_dl, eval_subpatch_predictions, config.labels_path, config.subpatch_to_patch_threshold, '2D_AE', True)  #for saving predictions\n",
    "disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics(eval_coord_dl, eval_subpatch_predictions, config.labels_path, config.subpatch_to_patch_threshold)\n",
    "print(\"Disease cluster:\", disease)\n",
    "print(\"Accuracy:\",acc)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1-score:\",f1_score)\n",
    "print(\"F2-score:\", f2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep: 3D_AE_B10 with encodings\n",
    "\n",
    "Data: Extracted and Pre-processed Patches (each patch containing a sugarbeet field)\n",
    "\n",
    "Dimensions: (N, T, C, H, W) = (N, 7, 10, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_pipeline = PreProcessingPipelineTemporal()\n",
    "\n",
    "# preprocessing_pipeline.run_temporal_patch_save_pipeline(type='train')\n",
    "# preprocessing_pipeline.run_temporal_patch_save_pipeline(type='eval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1491, 4, 10, 64, 64]), torch.Size([33, 4, 10, 64, 64]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline = PreProcessingPipelineTemporal()\n",
    "\n",
    "field_numbers_train, acquisition_dates_train, date_emb_train, patch_tensor_train, images_visualisation_train = preprocessing_pipeline.get_processed_temporal_cubes('train', 'b10_add', method='sin-cos',data_year='2024')\n",
    "field_numbers_eval, acquisition_dates_eval, date_emb_eval, patch_tensor_eval, images_visualisation_eval = preprocessing_pipeline.get_processed_temporal_cubes('eval', 'b10_add', method='sin-cos', data_year='2024')\n",
    "patch_tensor_train.shape, patch_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Sub-Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50529, 4, 10, 4, 4]), torch.Size([1213, 4, 10, 4, 4]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subpatches, train_subpatch_coords, train_subpatch_date_emb = non_overlapping_sliding_window_with_date_emb(patch_tensor_train, field_numbers_train, date_emb_train, patch_size=config.subpatch_size)\n",
    "eval_subpatches, eval_subpatch_coords, eval_subpatch_date_emb = non_overlapping_sliding_window_with_date_emb(patch_tensor_eval, field_numbers_eval, date_emb_eval, patch_size=config.subpatch_size)\n",
    "train_subpatches.shape, eval_subpatches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get field numbers and co-ordinates as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1615767.0_12_20', 1213, 50529)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_coord_dataloader = get_string_fielddata(train_subpatch_coords)\n",
    "eval_coord_dataloader = get_string_fielddata(eval_subpatch_coords)\n",
    "eval_coord_dataloader[0], len(eval_coord_dataloader), len(train_coord_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Unlabeled data into 'train' and 'test' and create  Data Loaders\n",
    "\n",
    "\n",
    "The data loader function for MAE is used since it is designed to take temporal encodings additionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subpatches_dl, test_subpatches, train_field_numbers, test_field_numbers, train_date_embeddings, test_date_embeddings = train_test_split(\n",
    "    train_subpatches, train_coord_dataloader, train_subpatch_date_emb, test_size=1-config.ae_train_test_ratio, random_state=42\n",
    ")\n",
    "\n",
    "dataloader_train = create_data_loader_mae(train_subpatches_dl, train_field_numbers, train_date_embeddings, mae=False, batch_size=config.ae_batch_size, shuffle=True)\n",
    "dataloader_test = create_data_loader_mae(test_subpatches, test_field_numbers, test_date_embeddings, mae=False, batch_size=config.ae_batch_size, shuffle=False)\n",
    "dataloader_eval = create_data_loader_mae(eval_subpatches, eval_coord_dataloader, eval_subpatch_date_emb, mae=False, batch_size=config.ae_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prep: 3D_AE_B10 with encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved 3D Conv Autoencoder trained with temporal data\n",
    "Redefine the architecture because the object needs to be created to load saved checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3DAutoencoder_Time_Addition(nn.Module):\n",
    "    def __init__(self, in_channels, time_steps, latent_size, patch_size):\n",
    "        super(Conv3DAutoencoder_Time_Addition, self).__init__()\n",
    "\n",
    "        self.time_steps = time_steps\n",
    "        self.in_channels = in_channels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # --- Encoder (3D Convolutions) ---\n",
    "        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv3d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # --- Fully Connected Latent Space ---\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(256 * patch_size * patch_size * time_steps, 512)   \n",
    "        self.fc2 = nn.Linear(512, latent_size)\n",
    "\n",
    "        # --- Decoder (Fully Connected) ---\n",
    "        self.fc3 = nn.Linear(latent_size, 512)\n",
    "        self.fc4 = nn.Linear(512, 256 * patch_size * patch_size * time_steps)\n",
    "\n",
    "        # --- 3D Deconvolutions (Transpose convolutions) ---\n",
    "        self.unflatten = nn.Unflatten(1, (256, time_steps, patch_size, patch_size))\n",
    "        self.deconv1 = nn.ConvTranspose3d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose3d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose3d(64, in_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # --- Temporal embedding projection to match channels (needed for alignment) ---\n",
    "        self.temb_proj = nn.Conv3d(2, in_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x, date_embeddings):\n",
    "\n",
    "        # --- Date embedding processing ---\n",
    "        # Convert the date embeddings to the shape (B, 2, 7, 4, 4)\n",
    "        if not isinstance(date_embeddings, torch.Tensor):\n",
    "            date_embeddings_tensor = torch.tensor(date_embeddings, dtype=torch.float32).to(x.device)    # Shape: (B, 7, 2)\n",
    "        date_embeddings_tensor = date_embeddings_tensor.permute(0, 2, 1)                                # Shape: (B, 2, 7)\n",
    "        date_embeddings_tensor = date_embeddings_tensor.unsqueeze(-1).unsqueeze(-1)                     # Shape: (B, 2, 7, 1, 1)\n",
    "        date_embeddings_tensor = date_embeddings_tensor.expand(-1, -1, -1, x.shape[3], x.shape[4])      # Shape: (B, 2, 7, 4, 4)\n",
    "\n",
    "        # Project the date embeddings to match the channels\n",
    "        date_embeddings_tensor = self.temb_proj(date_embeddings_tensor)                                 # Shape: (B, 10, 7, 4, 4)\n",
    "        # print('x shape before time embedding:',x.shape)\n",
    "        # print('time embeddings:',date_embeddings_tensor.shape)\n",
    "        \n",
    "        # --- Add date embeddings to the input tensor ---\n",
    "        x = x + date_embeddings_tensor                                                                  # Shape: (B, 10, 7, 4, 4)\n",
    "        # print('x shape after time embedding',x.shape)\n",
    "        \n",
    "        # --- Encoder ---\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        # --- Flatten and Fully Connected ---\n",
    "        b, c, t, h, w = x.shape                 # (B, C, T, H, W)\n",
    "        x = self.flatten(x)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        z = self.fc2(x)                         # Bottleneck    \n",
    "\n",
    "        # --- Decoder ---\n",
    "        x = F.relu(self.fc3(z))\n",
    "        x = F.relu(self.fc4(x))\n",
    "\n",
    "        # --- Reshape and 3D Deconvolutions ---\n",
    "        x = self.unflatten(x)                   # (B, C, H, W, T)\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x_reconstructed = self.deconv3(x)       # Reconstruction\n",
    "\n",
    "        return z, x_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "epochs = 50\n",
    "momentum=0.9\n",
    "lr = 0.001\n",
    "vae_lr=0.001\n",
    "latent_dim = 32\n",
    "channels = 10\n",
    "time_steps = 4\n",
    "optimizer = 'Adam'\n",
    "vae_optimizer = 'Adam'\n",
    "patch_size = config.subpatch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  3D_AE_temporal_addition_2024  trained\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"3D_AE_temporal_addition_2024\"]\n",
    "model_objs = [Conv3DAutoencoder_Time_Addition]  \n",
    "train_loss = {}\n",
    "test_loss = {}\n",
    "metrics = {}\n",
    "\n",
    "for name, obj in zip(model_names, model_objs):\n",
    "    avg_train_loss, avg_test_loss, avg_metrics = train_model_multiple_runs_with_metrics(\n",
    "        model_name=name,\n",
    "        model_class=obj,\n",
    "        dataloader_train=dataloader_train,\n",
    "        dataloader_test=dataloader_test,\n",
    "        dataloader_eval=dataloader_eval,\n",
    "        channels=channels,\n",
    "        timestamps=time_steps,\n",
    "        epochs=epochs,\n",
    "        optimizer=optimizer,\n",
    "        lr=lr,\n",
    "        vae_lr=vae_lr,\n",
    "        vae_optimizer=vae_optimizer,\n",
    "        momentum=momentum,\n",
    "        device=device,\n",
    "        config=config,\n",
    "        output_dir=config.results_json_path\n",
    "    )\n",
    "    print(\"Model \",name,\" trained\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['3D_AE_temporal_addition', \"3D_AE_temporal_addition_2024\"]\n",
    "df_loss, df_accuracy, df_recall, df_f1, df_precision = compile_results_table_with_metrics(model_names, output_dir=config.results_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Run 1</th>\n",
       "      <th>F1 Run 2</th>\n",
       "      <th>F1 Run 3</th>\n",
       "      <th>F1-score Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D_AE_temporal_addition</td>\n",
       "      <td>75.32</td>\n",
       "      <td>75.32</td>\n",
       "      <td>75.00</td>\n",
       "      <td>75.213333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D_AE_temporal_addition_2024</td>\n",
       "      <td>88.89</td>\n",
       "      <td>84.06</td>\n",
       "      <td>88.89</td>\n",
       "      <td>87.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  F1 Run 1  F1 Run 2  F1 Run 3  F1-score Avg\n",
       "0       3D_AE_temporal_addition     75.32     75.32     75.00     75.213333\n",
       "1  3D_AE_temporal_addition_2024     88.89     84.06     88.89     87.280000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Run 1</th>\n",
       "      <th>Accuracy Run 2</th>\n",
       "      <th>Accuracy Run 3</th>\n",
       "      <th>Accuracy Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D_AE_temporal_addition</td>\n",
       "      <td>68.85</td>\n",
       "      <td>68.85</td>\n",
       "      <td>70.49</td>\n",
       "      <td>69.396667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D_AE_temporal_addition_2024</td>\n",
       "      <td>80.00</td>\n",
       "      <td>72.50</td>\n",
       "      <td>80.00</td>\n",
       "      <td>77.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Accuracy Run 1  Accuracy Run 2  \\\n",
       "0       3D_AE_temporal_addition           68.85           68.85   \n",
       "1  3D_AE_temporal_addition_2024           80.00           72.50   \n",
       "\n",
       "   Accuracy Run 3  Accuracy Avg  \n",
       "0           70.49     69.396667  \n",
       "1           80.00     77.500000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall Run 1</th>\n",
       "      <th>Recall Run 2</th>\n",
       "      <th>Recall Run 3</th>\n",
       "      <th>Recall Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D_AE_temporal_addition</td>\n",
       "      <td>82.86</td>\n",
       "      <td>82.86</td>\n",
       "      <td>77.14</td>\n",
       "      <td>80.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D_AE_temporal_addition_2024</td>\n",
       "      <td>91.43</td>\n",
       "      <td>82.86</td>\n",
       "      <td>91.43</td>\n",
       "      <td>88.573333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Recall Run 1  Recall Run 2  Recall Run 3  \\\n",
       "0       3D_AE_temporal_addition         82.86         82.86         77.14   \n",
       "1  3D_AE_temporal_addition_2024         91.43         82.86         91.43   \n",
       "\n",
       "   Recall Avg  \n",
       "0   80.953333  \n",
       "1   88.573333  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision Run 1</th>\n",
       "      <th>Precision Run 2</th>\n",
       "      <th>Precision Run 3</th>\n",
       "      <th>Precision Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D_AE_temporal_addition</td>\n",
       "      <td>69.05</td>\n",
       "      <td>69.05</td>\n",
       "      <td>72.97</td>\n",
       "      <td>70.356667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D_AE_temporal_addition_2024</td>\n",
       "      <td>86.49</td>\n",
       "      <td>85.29</td>\n",
       "      <td>86.49</td>\n",
       "      <td>86.090000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Precision Run 1  Precision Run 2  \\\n",
       "0       3D_AE_temporal_addition            69.05            69.05   \n",
       "1  3D_AE_temporal_addition_2024            86.49            85.29   \n",
       "\n",
       "   Precision Run 3  Precision Avg  \n",
       "0            72.97      70.356667  \n",
       "1            86.49      86.090000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2019 vs 2024 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAJNCAYAAACsgOMnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAaB5JREFUeJzt3XdcVvX///EnIFuGgIArB7m3uFfubU5Q05yJqaTZx4aaaW4rR25bWgm5UjNLc2TlXmlpzkwN9wRUFAXO749+XN+uQEUOyPBxv92u203e533OeR06XVzP67zP+9gYhmEIAAAAAEywzegCAAAAAGR9BAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKZlqmDxyy+/qHXr1sqbN69sbGy0atUqq+WGYeidd95Rnjx55OzsrEaNGunEiRNWfa5fv66uXbvK3d1dnp6e6tOnj27duvUEjwIAAAB4+mSqYHH79m2VL19es2fPTnb5e++9pxkzZmjevHnatWuXXF1d1bRpU929e9fSp2vXrvrjjz+0YcMGrVmzRr/88otCQkKe1CEAAAAATyUbwzCMjC4iOTY2Nlq5cqXatm0r6Z+rFXnz5tX//vc/DR06VJIUFRUlPz8/LVy4UJ07d9aRI0dUqlQp7dmzR5UrV5YkrVu3Ti1atNDZs2eVN2/ejDocAAAAIFvLkdEFpNSpU6d08eJFNWrUyNLm4eGhatWqaceOHercubN27NghT09PS6iQpEaNGsnW1la7du1Su3btkt12bGysYmNjLT8nJCTo+vXr8vb2lo2NTfodFAAAAJCJGYahmzdvKm/evLK1ffhgpywTLC5evChJ8vPzs2r38/OzLLt48aJ8fX2tlufIkUNeXl6WPsmZOHGi3n333TSuGAAAAMgeIiIilD9//of2yTLBIj0NGzZMr732muXnqKgoPfPMM4qIiJC7u3sGVgYAAABknOjoaBUoUEBubm6P7JtlgoW/v78k6dKlS8qTJ4+l/dKlS6pQoYKlz+XLl63Wi4uL0/Xr1y3rJ8fR0VGOjo5J2t3d3QkWAAAAeOql5PaATDUr1MMULlxY/v7+2rRpk6UtOjpau3btUo0aNSRJNWrUUGRkpPbt22fp8+OPPyohIUHVqlV74jUDAAAAT4tMdcXi1q1b+vPPPy0/nzp1SgcOHJCXl5eeeeYZvfrqqxo3bpyKFi2qwoULa+TIkcqbN69l5qiSJUuqWbNm6tu3r+bNm6f79+8rNDRUnTt3ZkYoAAAAIB1lqmCxd+9e1a9f3/Jz4n0PPXr00MKFC/XGG2/o9u3bCgkJUWRkpGrXrq1169bJycnJsk5YWJhCQ0PVsGFD2draqkOHDpoxY8YTPxYAAADgaZJpn2ORkaKjo+Xh4aGoqKiH3mMRHx+v+/fvP8HKnk729vays7PL6DIAAACeOin9XCxlsisWWYVhGLp48aIiIyMzupSnhqenp/z9/XmuCAAAQCZFsEiFxFDh6+srFxcXPuymI8MwFBMTY5nt698zggEAACDzIFg8pvj4eEuo8Pb2zuhyngrOzs6SpMuXL8vX15dhUQAAAJlQlpluNrNIvKfCxcUlgyt5uiT+vrmnBQAAIHMiWKQSw5+eLH7fAAAAmRvBAgAAAIBpBAsAAAAAphEsnmLLli1TmzZtlD9/frm6uqpChQr67LPP9N9Hm3z66acqVqyYnJycVL58ea1Zs8Zq+Z49e9S7d289++yzcnFxUdGiRTVs2DDdvn37gfs+e/ascubMKRsbG129ejVdjg8AAABPDrNCpaGCH2bcvs8Mfvx1pk6dqkKFCmnKlCnKnTu3NmzYoL59+yoiIkKjRo2SJC1evFh9+/bViBEj1KBBAy1ZskTt2rXTli1bVL16dUnSkiVLdOLECb3xxhsqVqyY/vjjD73zzjvatWuXfvzxx2T3/b///U85c+Z8aPgAAABA1sGTt5PxsCcM3r17V6dOnVLhwoXl5ORktSyrBYurV6/Kx8fHqi0kJERLlizRjRs3ZGtrq+LFiyswMFDh4eGWPjVr1pSnp6e+//57SdKVK1eUO3duq+2Eh4era9eu2rt3rwIDA62W/fjjjwoKCtLw4cM1dOhQXblyJUkd//Ww3zsAAADSx+M8eZuhUE+x5D7MV6xYUdHR0bp9+7b++usvHT9+XMHBwVZ9OnfurE2bNik2NlaSkoSKxO1I0vnz563a79+/r9DQUL377rs8BwQAACAbIVjAytatW5UvXz65ubnp6NGjkqQSJUpY9SlZsqTu3bunU6dOPXQ7ya374Ycfys7OTv3790/jygEAAJCRuMcCFlu3btXixYs1ZcoUSdKNGzckSZ6enlb9cuXKJUm6fv16stu5evWqRo8erTZt2qho0aKW9vPnz2vMmDFatWoVT88GAADIZrhiAUn/zNLUqVMn1a9fX4MGDUr1du7fv6/OnTtLkubOnWu1bOjQoWrcuLEaNGhgqlYAAABkPlyxgCIjI9W8eXN5e3vr66+/lq3tP3kz8cpEVFSU/P39Lf0Tr2R4eXlZbccwDPXu3Vu7d+/Wli1blCdPHsuyHTt2aPny5dq1a5ciIyMlSTExMZL+uSnIxcVFLi4u6XaMAAAASF8Ei6fcnTt31KpVK0VFRWnHjh3y8PCwLEu8P+Lo0aMqXry4pf3o0aNycHBQkSJFrLY1dOhQLV26VN9//73Kly9vtezYsWO6f/++KlWqlKSGgIAAderUSYsXL07LQwMAAMATRLB4isXFxSk4OFhHjhzRli1blC9fPqvlRYoUUbFixSwP0ku0ZMkSNWzYUA4ODpa2SZMmadq0aQoLC1PDhg2T7KtZs2bavHmzVdu6des0efJkrVq1yupeDAAAAGQ9BIun2IABA7RmzRpNmTJF0dHR2rlzp2VZxYoV5ejoqNGjR6tr164KCAhQ/fr1tWTJEu3atUu//PKLpW94eLiGDRumbt26qXDhwlbbCQgIUO7cueXv7281nEqSTp8+LUmqVavWI59jAQAAgMyNYJGGUvOQuoy0fv16Sf88Bfu/Tp06pUKFCqlLly6KiYnRpEmTNGnSJBUvXlwrV65UjRo1kmxn0aJFWrRokdV2FixYoJ49e6bfQQAAACBT4MnbyUjtk7eRfvi9AwAAPHk8eRsAAADAE0WwAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsEiLdnYZNwrFZYtW6Y2bdoof/78cnV1VYUKFfTZZ5/JMAyrfp9++qmKFSsmJycnlS9fXmvWrLFafu/ePb3xxhuqW7euXF1dZWNjo6tXrya7zwULFqhEiRJydHTUs88+q5kzZ6aqdgAAAGQuBIun2NSpU+Xi4qIpU6bo22+/VfPmzdW3b1+NGTPG0mfx4sXq27evOnXqpLVr16pGjRpq166ddu7caekTExOjjz/+WE5OTqpTp84D97d06VL17t1bzZo105o1a/TCCy9oyJAhmjVrVroeJwAAAJ4AA0lERUUZkoyoqKgky+7cuWMcPnzYuHPnTtIVpYx7pcKVK1eStPXt29dwd3c34uPjDcMwjGLFihldunSx6lOjRg2jefPmVm0JCQmGYRjGggULDEnJbrt48eJG+/btrdpCQ0MNb29v4969ew+t9aG/dwDIQMePHzc6depk5MuXz3B2djaKFy9uvPvuu8bt27ctfeLj4425c+ca5cuXN1xdXQ1fX1+jWbNmxrZt21K0D0nJviZOnGjVr2DBgg/s++yzz6bpcQN4Ojzsc/F/5ciALINMwsfHJ0lbxYoV9fHHH+v27du6cuWKjh8/rsmTJ1v16dy5s15//XXFxsbK0dFRkmTziOFYMTExOn78uIYMGWLV3rRpU82aNUs7duxQ3bp1TR4RADxZERERqlq1qjw8PBQaGiovLy/t2LFDo0aN0r59+/TNN99Ikl5//XVNnTpV3bp104ABAxQZGan58+frueee07Zt21S1atVH7qtx48bq3r27VVvFihWtfp4+fbpu3bpl1XbmzBm9/fbbatKkicmjBYCHI1jAytatW5UvXz65ublpy5YtkqQSJUpY9SlZsqTu3bunU6dOJVn2ILGxsTIMwxJEEiX+fOTIEYIFgCznyy+/VGRkpLZu3arSpUtLkkJCQpSQkKAvvvhCN27ckJubm+bOnauOHTvqyy+/tKwbFBSkIkWKKCwsLEXBolixYurWrdtD+7Rt2zZJ27hx4yRJXbt2fYwjA4DHxz0WsNi6dasWL16soUOHSpJu3LghSfL09LTqlytXLknS9evXU7ztXLlyydvbW7t377ZqT7xX43G2BQCZRXR0tCTJz8/Pqj1PnjyytbWVg4OD7t+/rzt37iTp4+vrK1tbWzk7O6d4f3fu3NHdu3cfq8bw8HAVLlxYNWvWfKz1AOBxESwgSTp79qw6deqk+vXra9CgQemyjwEDBmjBggUKDw/XjRs3tGbNGn344YeSHj2UCgAyo3r16kmS+vTpowMHDigiIkJLlizR3LlzNWjQILm6usrZ2VnVqlXTwoULFRYWpr///lu///67evbsqVy5cikkJCRF+1q4cKFle6VKlVJ4ePgj19m/f7+OHDmiF154wcxhAkCKMBQKioyMVPPmzeXt7a2vv/5atrb/5M3EKxNRUVHy9/e39E+8kuHl5fVY+xk2bJhOnjypbt26yTAMubq6avLkyQoNDVWePHnS6GgA4Mlp1qyZxo4dqwkTJmj16tWW9hEjRliGIEnSokWL1KlTJ6uhTEWKFNG2bdtUpEiRR+6nZs2aCg4OVuHChXX+/HnNnj1bXbt2VVRUlPr37//A9cLCwiQxDArAk0GweMrduXNHrVq1UlRUlHbs2CEPDw/LssT7J44eParixYtb2o8ePSoHB4cU/TH8N2dnZ4WFhWn69Om6ePGiihQposOHD0uSqlevngZHAwBPXqFChVS3bl116NBB3t7e+u677zRhwgT5+/srNDRUkuTm5qbSpUurRo0aatiwoS5evKhJkyapbdu22rJlS7KTafzbtm3brH7u3bu3AgMDNXz4cPXs2TPZ4VQJCQlavHixKlasqJIlS6bdAQPAAzAU6ikWFxen4OBgHTlyROvWrVO+fPmslhcpUkTFihXTsmXLrNqXLFmihg0bysHBIVX7zZ07t8qWLStXV1fNmjVLderUsQouAJBVLF68WCEhIfrkk0/Ut29ftW/fXp9++ql69OihN998U9euXVNcXJwaNWokDw8PzZo1S+3atVP//v21ceNGnTx5Uu+///5j79fBwUGhoaGKjIzUvn37ku3z888/69y5c1ytQIqdOHFCnTt3Vv78+eXi4qISJUpozJgxiomJkSSdPn1aNjY2D3z17dv3oduPiIjQu+++q6pVqypXrlzy8fFRvXr1tHHjxmT779u3T61atZK/v79y5sypcuXKacaMGYqPj0/zY0fa4IrFU2zAgAFas2aNpkyZoujoaKuH3lWsWFGOjo4aPXq0unbtqoCAANWvX19LlizRrl279Msvv1hta+3atbp9+7b27t0rSfr222/l5uamUqVKqVSpUpY+f/75p0qXLq3r168rLCxMmzdvTvJNHABkFXPmzFHFihWVP39+q/bnn39eCxcu1P79+2Vra6tDhw5p6tSpVn2KFi2qkiVLpvo9sECBApIePPlFWFiYbG1t1aVLl1RtH0+XlEydnDt3bquZzRKtW7dOYWFhj5zS+JtvvtHkyZPVtm1b9ejRQ3Fxcfriiy/UuHFjffbZZ+rVq5el7759+1SzZk0VLVpUb775plxcXLR27VoNHjxYJ0+etNyjiUwm3Z+qkQWl+gF5WczDHqR06tQpS79PPvnEePbZZw0HBwejbNmyxrfffpvibY0aNcrSZ/369Ub58uUNFxcXw8PDw2jTpo1x+PDhFNWanX7vALKPYsWKGdWqVUvSvmTJEkOSsXbtWiM8PNzy7/8qWbJksuunxMyZMw1Jxvbt25Msu3v3ruHp6Wk0aNAgVdvG02f8+PGGJOPQoUNW7d27dzckGdevX3/gug0bNjTc3d0f+Tf60KFDSR6ge/fuXaNEiRJG/vz5rdr79u1rODg4GNeuXbNqr1u3ruHu7p6SQ0Ia4QF5SJHTp0+nqF+fPn3Up08f09tq3LixDhw4kKJ9AkBWUKxYMa1fv17Hjx9XsWLFLO1fffWVbG1tVa5cOV24cEHSP8OmmjVrZunz66+/6tixY1azQsXExOjvv/+Wj4+P5b6LK1euKHfu3Fb7vXnzpqZPny4fHx8FBgYmqev7779XZGQkw6CQYimZOjk5Fy5c0ObNm9W9e3c5OTk9dB+Jz3r5N0dHR7Vo0UJTp07VzZs35ebmZqnHyckpyZT3efLk0bFjx1J6WHjCuMcCAIBUev311xUfH686depo7NixmjNnjlq0aKFVq1apd+/eyps3rwIDA9W4cWN9/vnnat++vebNm6dRo0apUaNGcnZ21quvvmrZ3u7du1WyZEnNmjXL0jZ79mxVqFBBI0eO1Mcff6wxY8aobNmy+uuvvzR9+vRkP/CFhYXJ0dFRHTp0eBK/BmQDKZk6OTmLFy9WQkKCqRB78eJFubi4yMXFxaqe6Oho9evXT0eOHNGZM2c0b948rVixQsOGDUv1vpDOnsAVlCznaRkKlZXweweQWe3atcto3ry54e/vb9jb2xvFihUzxo8fb9y/f9/SJyYmxhgzZoxRqlQpw9nZ2fDw8DBatWpl7N+/32pbmzdvTnYYaePGjS3b9/T0NJo0aWJs2rQp2XqioqIMJycno3379ulxuMjGxo4dazg7O1sNaR4xYsRD1wkMDDTy5MljxMfHp2qfJ06cMJycnIwXX3zRqj0uLs4IDQ017O3tLbXY2dkZc+fOTdV+kHqPMxTKxjAMI+NiTeYUHR0tDw8PRUVFyd3d3WrZ3bt3derUKRUuXPiRl/yQdvi9AwCQvhYtWqRFixZZTZ28YMECzZgxwzJ18r8dP35cxYsX15AhQ5JMTpASMTExqlWrls6cOaNDhw4pb968VsunT5+uTZs2KSgoSE5OTvrqq6+0Zs0aLVu2TG3btk3tYeIxPexz8X8xFApAhnjUtIaJ7t27pwkTJqhEiRJycnKSn5+fWrZsqbNnz6ZoP59++qlKliwpJycnFS1aVDNnzky23+LFi1WpUiU5OTkpd+7c6tOnj65evWr6OAEgK0jJ1Mn/ZeYBjPHx8ercubMOHz6s5cuXJwkVkyZN0uTJk/XVV1+pe/fuCg4O1sqVK1W7dm0NHDhQcXFxqTtQpCuCRSpxoefJ4vedvSROa7hz506FhoZq+vTpqlGjhkaNGmU1Neb9+/fVsmVLjR8/Xs2aNdOcOXP0xhtvyNXVVVFRUY/cz/z58/XSSy+pdOnSmjlzpmrUqKFBgwZp8uTJVv3mzp2rLl26yMvLS1OnTlXfvn21ePFiNWzYUHfv3k3z4weAzOZhUyfHxMRo//79SdYJDw9X8eLFk51A4FH69u2rNWvWaOHChWrQoEGy9TRo0EA5c+ZMUs/58+dTPAENnixmhXpM9vb2kv65fJfck06RPhK/xU78/SNr+/LLLxUZGamtW7daZgkJCQlRQkKCvvjiC924cUO5cuXStGnT9PPPP2vr1q2qWrXqY+3jzp07GjFihFq2bKnly5dL+ucPWUJCgsaOHauQkBDlypVL9+7d0/Dhw1W3bl1t2LBBNjY2kqSaNWuqdevW+vjjj/XKK6+k7S8AADKZS5cuKVeuXEna79+/L0lJrhDs2rVLf/75p8aMGfPY+3r99de1YMECTZ8+/YHPWbl06VKyD8J7UD3IHAgWj8nOzk6enp66fPmyJMnFxcXyQQRpzzAMxcTE6PLly/L09JSdnV1Gl4Q0kJJpDRMSEvThhx+qXbt2qlq1quLi4nTv3j2rWUMeZvPmzbp27ZoGDBhg1T5w4ECFhYXpu+++U7du3XTo0CFFRkaqU6dOVv8vt2rVSjlz5tTixYsJFgCyvZRMnfxv4eHhkqQXXngh2e0lN3WyJL3//vv64IMPNHz4cA0ePPih9WzYsEHXrl2Tt7e3pH+GTy1dulRubm4KCAhI9bEi/RAsUsHf31+SLOEC6c/T09Pye0fWV69ePU2ePFl9+vTRu+++K29vb23fvt1qWsNDhw7p/PnzKleunEJCQvT555/r3r17Klu2rD788EPVr1//oftIvGxfuXJlq/bAwEDZ2tpq//796tatm2JjYyUp2SuQzs7O2r9/vxISEmRry8hRANnX66+/rrVr16pOnToKDQ2Vt7e31qxZo7Vr1+qll16yugciPj5eS5YsUfXq1R/4AX/37t2qX7++Ro0apdGjR0uSVq5cqTfeeMPy1PlFixZZrdO4cWPLF05vvfWWunXrpmrVqikkJETOzs766quvtG/fPo0bN44RDJkUwSIVbGxslCdPHvn6+louySH92Nvbc6Uim2nWrJnGjh2rCRMmaPXq1Zb2ESNGaNy4cZL+ublbkqZNmyYvLy/Nnz9fkjRhwgQ1a9ZMe/bsSfIN2r9duHBBdnZ28vX1tWp3cHCQt7e3zp8/L0kqWrSobGxstG3bNvXq1cvS79ixY7py5Yok6caNG5ZvzAAgO6pbt662b9+u0aNHa86cObp27ZoKFy6s8ePH64033rDqu3HjRl26dEkjRox4rH389ttvkv55f3/xxReTLN+8ebMlWHTt2lU+Pj6aOHGi3n//fUVHR6t48eKaN2+e+vXrl8qjRHojWJhgZ2fHB14glQoVKqS6detaTWs4YcIE+fv7KzQ0VLdu3ZL0zxOG9+/frwIFCkiSGjRooGeffVbvvfdekm+7/u3OnTsPfFKsk5OT7ty5I0ny8fFRcHCwPv/8c5UsWVLt2rXTuXPn9Morr8je3l7379+39AWA7Kxq1ar6/vvvH9mvadOmj5xUpV69ekn6jB492nL1IiWaNm2qpk2bprg/Mh7BAsATlzit4fHjxy0zkLRv314JCQl688031aVLF8vQpFq1allChSQ988wzql27trZv3/7QfTg7O+vevXvJLrt7967V0Kf58+frzp07Gjp0qIYOHSpJ6tatmwICArRixYoks5IAAICkCBYAnriHTWu4cOFC7d+/3zKe9783eEuSr69vslMf/luePHkUHx+vy5cvWw2Hunfvnq5du2Y1XtjDw0PffPON/v77b50+fVoFCxZUwYIFVbNmTeXOnVuenp4mjhbZScEPM7qC9HHmwffQAkCKcTcigCcuJdMIli1bVvb29jp37lySfufPn1fu3Lkfuo8KFSpIkvbu3WvVvnfvXiUkJFiW/9szzzyjunXrqmDBgoqMjNS+ffvUqFGjFB4VAABPN4IFgCeuWLFi2r9/v44fP27V/u9pDd3c3NSiRQtt375dR48etfQ5cuSItm/frsaNG1vaYmJidPToUasnZTdo0EBeXl6aO3eu1T7mzp0rFxcXtWzZ8qE1Dhs2THFxcRoyZIiZQwUA4KnBUCgAT1xKpzWcMGGCNm3apAYNGmjQoEGSpBkzZsjLy0vDhw+3bC+5aQ2dnZ01duxYDRw4UEFBQWratKm2bNmiRYsWafz48fLy8rKsP2nSJB06dEjVqlVTjhw5tGrVKq1fv17jxo1TlSpVntwvBgCALIxgAeCJS+m0hqVKldLPP/+sN998U+PGjZOtra0aNGig999/X/ny5XvkfgYMGCB7e3tNmTJFq1evVoECBTRt2rQkD2UqW7asVq5cqdWrVys+Pl7lypXT0qVLFRQUlObHDgBAdmVjPGq+sKdQdHS0PDw8FBUVJXd394wuBwCQSXDzNoCnzeN8LuYeCwAAAACmMRQKAADgKcPVN6QHrlgAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjVmhAKQrZh4BAODpwBULAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAABAEidOnFDnzp2VP39+ubi4qESJEhozZoxiYmKs+m3fvl21a9eWi4uL/P39NWjQIN26dStF+7h06ZJ69eolX19fOTs7q1KlSlq2bFmSfqNHj5aNjU2Sl5OTU5ocK4C0wXSzAADASkREhKpWrSoPDw+FhobKy8tLO3bs0KhRo7Rv3z598803kqQDBw6oYcOGKlmypKZOnaqzZ8/qgw8+0IkTJ7R27dqH7iM6Olq1a9fWpUuXNHjwYPn7+2vp0qUKDg5WWFiYXnjhhSTrzJ07Vzlz5rT8bGdnl7YHDsAUggUAALDy5ZdfKjIyUlu3blXp0qUlSSEhIUpISNAXX3yhGzduKFeuXBo+fLhy5cqln376Se7u7pKkQoUKqW/fvlq/fr2aNGnywH3Mnz9ff/75pzZt2qQGDRpIkvr376/q1avrf//7nzp27CgHBwerdTp27CgfH590OmoAZjEUCgAAWImOjpYk+fn5WbXnyZNHtra2cnBwUHR0tDZs2KBu3bpZQoUkde/eXTlz5tTSpUsfuo8tW7Yod+7cllAhSba2tgoODtbFixf1888/J1nHMAxFR0fLMAwzhwcgnRAsAACAlXr16kmS+vTpowMHDigiIkJLlizR3LlzNWjQILm6uurgwYOKi4tT5cqVrdZ1cHBQhQoVtH///ofuIzY2Vs7OzknaXVxcJEn79u1LsqxIkSLy8PCQm5ubunXrpkuXLqXyCAGkB4ZCAQAAK82aNdPYsWM1YcIErV692tI+YsQIjRs3TpJ04cIFSf9cxfivPHnyaMuWLQ/dR/HixbVx40adOXNGBQsWtLQnrnfu3DlLW65cuRQaGqoaNWrI0dFRW7Zs0ezZs7V7927t3bvX6ooJgIxDsAAAAEkUKlRIdevWVYcOHeTt7a3vvvtOEyZMkL+/v0JDQ3Xnzh1JkqOjY5J1nZycLMsf5KWXXtK8efMUHBysadOmyc/PT0uXLtXKlSslyWr9wYMHW63boUMHVa1aVV27dtWcOXP01ltvmT1cAGmAoVAAAMDK4sWLFRISok8++UR9+/ZV+/bt9emnn6pHjx568803de3aNcswptjY2CTr3717N9lhTv9Wrlw5hYeH6+TJk6pVq5aeffZZzZgxQ9OnT5ckq9mfkvPCCy/I399fGzduTN1BAkhzBAsAAGBlzpw5qlixovLnz2/V/vzzzysmJkb79++3DIFKHBL1bxcuXFDevHkfuZ+OHTvq/Pnz2r17t3bs2KEzZ86oSJEikqRixYo9cv0CBQro+vXrKTkkAE8AwQIAAFi5dOmS4uPjk7Tfv39fkhQXF6cyZcooR44c2rt3r1Wfe/fu6cCBA6pQoUKK9uXg4KAqVaqoevXqcnBwsFyBaNSo0UPXMwxDp0+fVu7cuVO0HwDpj2ABAACsFCtWTPv379fx48et2r/66ivZ2tqqXLly8vDwUKNGjbRo0SLdvHnT0ufLL7/UrVu3FBQUZGmLiYnR0aNHdfXq1Yfu98SJE5o3b55atWpldcXiypUrSfrOnTtXV65cUbNmzVJ7mADSGDdvAwAAK6+//rrWrl2rOnXqKDQ0VN7e3lqzZo3Wrl2rl156yTLMafz48apZs6aee+45hYSE6OzZs5oyZYqaNGli9YF/9+7dql+/vkaNGqXRo0db2kuVKqWgoCA988wzOnXqlObOnSsvLy/NmzfPqp6CBQuqU6dOKlu2rJycnLR161YtXrxYFSpUUL9+/Z7I7wTAoxEsAACAlbp162r79u0aPXq05syZo2vXrqlw4cIaP3683njjDUu/SpUqaePGjXrzzTc1ZMgQubm5qU+fPpo4cWKK9lO+fHktWLBAly5dko+Pj4KDg/Xuu+/K19fXql/Xrl21fft2ff3117p7964KFiyoN954QyNGjLA89wJAxrMxeHxlEtHR0fLw8FBUVBRzYwMmFfwwoytIH2cGP7oPsh/OZ2QXnMtIqcf5XMw9FgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWGQhPXv2lI2NzQNf586d0+nTpx/ap2/fvo/cz4PWnTRpUpK+586dU3BwsDw9PeXu7q42bdror7/+So/DBwAAQCbGcyyykH79+qlRo0ZWbYZh6OWXX1ahQoWUL18+3b59W19++WWSddetW6ewsDA1adIkRftq3LixunfvbtVWsWJFq59v3bql+vXrKyoqSsOHD5e9vb2mTZum5557TgcOHJC3t/djHiEAAACyKoJFFlKjRg3VqFHDqm3r1q2KiYlR165dJUmurq7q1q1bknUXLlwod3d3tW7dOkX7KlasWLLb+bc5c+boxIkT2r17t6pUqSJJat68ucqUKaMpU6ZowoQJKdoXAAAAsj6GQmVx4eHhsrGx0QsvvPDAPhcuXNDmzZvVvn17OTk5pXjbd+7c0d27dx+4fPny5apSpYolVEhSiRIl1LBhQy1dujTF+wEAZDAbm+z3AvDEZalgER8fr5EjR6pw4cJydnZWQECAxo4dq38/PNwwDL3zzjvKkyePnJ2d1ahRI504cSIDq04/9+/f19KlS1WzZk0VKlTogf0WL16shIQEy1WNlFi4cKFcXV3l7OysUqVKKTw83Gp5QkKCfv/9d1WuXDnJulWrVtXJkyd18+bNFO8PAAAAWVuWChaTJ0/W3LlzNWvWLB05ckSTJ0/We++9p5kzZ1r6vPfee5oxY4bmzZunXbt2ydXVVU2bNn3oN+9Z1Q8//KBr1649MjCEhYUpT548atCgQYq2W7NmTY0fP16rVq3S3LlzZWdnp65du2ru3LmWPtevX1dsbKzy5MmTZP3EtvPnzz/G0QAAACAry1L3WGzfvl1t2rRRy5YtJUmFChXSV199pd27d0v652rF9OnT9fbbb6tNmzaSpC+++EJ+fn5atWqVOnfunGG1p4fw8HDZ29srODj4gX2OHz+uffv2aciQIbK1TVmO3LZtm9XPvXv3VmBgoIYPH66ePXvK2dlZd+7ckSQ5OjomWT9xuFViHwAAAGR/WeqKRc2aNbVp0yYdP35ckvTbb79p69atat68uSTp1KlTunjxotXMSR4eHqpWrZp27NjxwO3GxsYqOjra6pXZ3bp1S998842aNm360NmXwsLCJOmxhkH9l4ODg0JDQxUZGal9+/ZJkpydnSX987v7r8SrQ4l9AAAAkP1lqSsWb731lqKjo1WiRAnZ2dkpPj5e48ePt3xovnjxoiTJz8/Paj0/Pz/LsuRMnDhR7777bvoVng5WrVplNRvUg4SHh6t48eIKDAw0tb8CBQpI+mcIlCR5eXnJ0dFRFy5cSNI3sS1v3rym9gkAAICsI0tdsVi6dKnCwsIUHh6uX3/9VZ9//rk++OADff7556a2O2zYMEVFRVleERERaVRx+gkLC1POnDn1/PPPP7DPrl279Oeff5q6WpEo8aF3uXPnliTZ2tqqbNmy2rt3b7L7LVKkiNzc3EzvFwAAAFlDlgoWr7/+ut566y117txZZcuW1YsvvqghQ4Zo4sSJkiR/f39J0qVLl6zWu3TpkmVZchwdHeXu7m71ysyuXLmijRs3ql27dnJxcXlgv8SZnB40FW1MTIyOHj2qq1evWm37v27evKnp06fLx8fH6spHx44dtWfPHqtwcezYMf34448KCgp67OMCAABA1pWlgkVMTEySG5Dt7OyUkJAgSSpcuLD8/f21adMmy/Lo6Gjt2rUryYPlsrIlS5YoLi7uoVci4uPjtWTJElWvXl0BAQHJ9tm9e7dKliypWbNmWdpmz56tChUqaOTIkfr44481ZswYlS1bVn/99ZemT58uBwcHS98BAwYoICBALVu21Pvvv6/p06ercePG8vPz0//+97+0O2AAAABkelkqWLRu3Vrjx4/Xd999p9OnT2vlypWaOnWq2rVrJ0mysbHRq6++qnHjxmn16tU6ePCgunfvrrx586pt27YZW3waCgsLk6+vr9VN6v+1ceNGXbp06aEPzktOrVq15Ovrq08++UQDBw7UtGnTVLx4cW3cuDFJkHFzc9NPP/2kunXraty4cRo5cqTKly+vn3/+2TJkCgAAIKP07NlTNjY2D3ydO3dOklSvXr1klzdr1uyR+4iIiNC7776rqlWrKleuXPLx8VG9evW0cePGJH0vXLigt956S/Xr15ebm5tsbGz0008/pfVhZ5gsdfP2zJkzNXLkSA0YMECXL19W3rx51a9fP73zzjuWPm+88YZu376tkJAQRUZGqnbt2lq3bt1jPXE6s3vYDFeJmjZtavXgwOTUq1cvSZ/GjRurcePGKa4lf/78WrZsWYr7AwAAPCn9+vVL8kWsYRh6+eWXVahQIeXLl8/Snj9/fsvw+kQpmYjmm2++0eTJk9W2bVv16NFDcXFx+uKLL9S4cWN99tln6tWrl6XvsWPHNHnyZBUtWlRly5ZN0We6rMTGeNSnz6dQdHS0PDw8FBUVlenvtwAyu4IfZnQF6ePM4IyuABkh257Pr9pkdAlpj483D5Vtz+UUvDdv3bpVderU0fjx4zV8+HBJ/3zZevXqVR06dOix9/nHH3/Iz89PPj4+lrbY2FhVqFBBt27dspoU6ObNm7p//768vLy0fPlyBQUFafPmzapXr95j7/dJeZzPxVlqKBQAAABgRnh4uGxsbJIdLh4XF6dbt2491vZKly5tFSqkfyYGatGihc6ePaubN29a2t3c3OTl5ZW6wrMAggUAAACeCvfv39fSpUtVs2ZNFSpUyGrZ8ePH5erqKjc3N/n7+2vkyJG6f/9+qvd18eJFubi4PHQGz+wmS91jAQAAAKTWDz/8oGvXriWZkCYgIED169dX2bJldfv2bS1fvlzjxo3T8ePHtWTJksfez59//qkVK1YoKChIdnZ2aVV+pkewAAAAwFMhPDxc9vb2Cg4Otmr/9NNPrX5+8cUXFRISoo8//lhDhgxR9erVU7yPmJgYBQUFydnZWZMmTUqTurMKhkIBAAAg27t165a++eYbNW3aVN7e3o/sn/hMruSmjX2Q+Ph4de7cWYcPH9by5ctTNKtUdsIVCwAAAGR7q1atUkxMzEMfMPxvBQoUkCRdv349xfvo27ev1qxZo7CwMDVo0CBVdWZlBItM6mmeBg4AACCthYWFKWfOnHr++edT1P+vv/6SpBQ/9Pf111/XggULNH36dHXp0iXVdWZlDIUCAABAtnblyhVt3LhR7dq1SzJLU3R0tGJjY63aDMPQuHHjJP3z0OFEMTExOnr0qK5evWrV//3339cHH3yg4cOHa/Dgp/dbVK5YAAAAIFtbsmSJ4uLikh0G9euvv6pLly7q0qWLnn32Wd25c0crV67Utm3bFBISokqVKln67t69W/Xr19eoUaM0evRoSdLKlSv1xhtvqGjRoipZsqQWLVpktf3GjRvLz8/P8nNiYPnjjz8kSV9++aW2bt0qSXr77bfT9LifNIIFAAAAsrWwsDD5+vqqUaNGSZYVLFhQderU0cqVK3Xx4kXZ2tqqZMmSmjdvnkJCQh657d9++02SdOLECb344otJlm/evNkqWIwcOdJq+WeffWb5d1YPFjaGwTPv/+txHl2eXrjHAtkF5zKyk2x7Pr9qk9ElpD0+3jxUtj2XeW9Oc4/zuZh7LAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACm8eRtAAAAZA822fBhj1KWeeAjVywAAAAAmEawAAAAAGAawQIAAACAaQQLAEgjPXv2lI2NzQNf586ds/Tdvn27ateuLRcXF/n7+2vQoEG6devWI/dx584d9enTR2XKlJGHh4dy5syp8uXL68MPP9T9+/eTXWfjxo1q0KCBPDw85ObmpsDAQC1ZsiTNjhsAAImbtwEgzfTr10+NGjWyajMMQy+//LIKFSqkfPnySZIOHDighg0bqmTJkpo6darOnj2rDz74QCdOnNDatWsfuo87d+7ojz/+UIsWLVSoUCHZ2tpq+/btGjJkiHbt2qXw8HCr/gsWLFCfPn3UuHFjTZgwQXZ2djp27JgiIiLS9uABAE89ggUApJEaNWqoRo0aVm1bt25VTEyMunbtamkbPny4cuXKpZ9++knu7u6SpEKFCqlv375av369mjRp8sB9eHl5aefOnVZtL7/8sjw8PDRr1ixNnTpV/v7+kqTTp09r4MCBeuWVV/Thhx+m1WECAJAshkIBQDoKDw+XjY2NXnjhBUlSdHS0NmzYoG7dullChSR1795dOXPm1NKlS1O1n0KFCkmSIiMjLW3z5s1TfHy8xowZI0m6deuWjCwyZSEAIOshWABAOrl//76WLl2qmjVrWj74Hzx4UHFxcapcubJVXwcHB1WoUEH79+9P0bbv3bunq1evKiIiQitXrtQHH3ygggUL6tlnn7X02bhxo0qUKKHvv/9e+fPnl5ubm7y9vTVy5EglJCSk2XECACARLJBJ/Prrr3r++efl5eUlFxcXlSlTRjNmzLAsv3//vt59910VKVJEjo6OKlKkiMaNG6e4uLjH3tfWrVstN9NevXo1yfJz584pODhYnp6ecnd3V5s2bfTXX3+ZOj48nX744Qddu3bNahjUhQsXJEl58uRJ0j9Pnjw6f/58ira9YsUK5c6dW88884zat2+v/Pnz69tvv1WOHP83wvXEiROKiIhQr1691Lt3by1fvlzNmzfXuHHjNGLECJNHBwCANe6xQIZbv369WrdurYoVK2rkyJHKmTOnTp48qbNnz1r6dOvWTcuWLVPv3r1VuXJl7dy5UyNHjtTff/+tjz76KMX7SkhI0CuvvCJXV1fdvn07yfJbt26pfv36ioqK0vDhw2Vvb69p06bpueee04EDB+Tt7Z0mx4ynQ3h4uOzt7RUcHGxpu3PnjiTJ0dExSX8nJyfL8kepX7++NmzYoMjISG3atEm//fZbknP61q1bSkhI0KRJk/Tmm29Kkjp06KDr16/rww8/1PDhw+Xm5pbawwMAwArBAhkqOjpa3bt3V8uWLbV8+XLZ2ia9iLZnzx4tXbpUI0eOtIwVf/nll+Xj46OpU6cqNDRU5cqVS9H+PvroI0VEROill15K9mbWOXPm6MSJE9q9e7eqVKkiSWrevLnKlCmjKVOmaMKECSaOFk+TW7du6ZtvvlHTpk2tAqmzs7MkKTY2Nsk6d+/etSx/FD8/P/n5+UmSOnbsqAkTJqhx48Y6ceKE5eZtZ2dn3b59W126dLFat0uXLlq3bp3279+vunXrpur4AAD4L4ZCIUOFh4fr0qVLGj9+vGxtbXX79u0kY7+3bNkiSercubNVe+fOnWUYRorn479+/brefvttjRkzRp6ensn2Wb58uapUqWIJFZJUokQJNWzYMNU31eLptGrVqiSzQUn/NwQqcUjUv124cEF58+ZN1f46duxoCTOJEreVGEAS+fr6SpJu3LiRqn0BAJAcggUy1MaNG+Xu7q5z586pePHiypkzp9zd3dW/f3/dvXtX0v99s/vfb3JdXFwkSfv27UvRvkaOHCl/f3/169cv2eUJCQn6/fffk9xUK0lVq1bVyZMndfPmzRQfG55uYWFhypkzp55//nmr9jJlyihHjhzau3evVfu9e/d04MABVahQIVX7SxxCFRUVZWkLDAyUJKsH80my3MeRO3fuVO0LAIDkECyQoU6cOKG4uDi1adNGTZs21ddff63evXtr3rx56tWrlySpePHikqRt27ZZrZt4JeO/H5qS8/vvv2v+/PmaOnWq7Ozsku1z/fp1xcbGPvCmWkkpvrEWT7crV65o48aNateunSUAJ/Lw8FCjRo20aNEiq6D65Zdf6tatWwoKCrK0xcTE6OjRo1aTDFy9ejXZKWM/+eQTSbIKxp06dZIkffrpp5a2hIQELViwQF5eXpbgAQBAWuAeC2SoW7duKSYmRi+//LJlFqj27dvr3r17mj9/vsaMGaMWLVqoYMGCGjp0qFxcXBQYGKhdu3ZpxIgRypEjR4pudh00aJCaN2/+0AePPeqm2n/3AR5myZIliouLSzIMKtH48eNVs2ZNPffccwoJCdHZs2c1ZcoUNWnSRM2aNbP02717t+rXr69Ro0Zp9OjRkqRFixZp3rx5atu2rYoUKaKbN2/qhx9+0IYNG9S6dWs1aNDAsn6bNm3UsGFDTZw4UVevXlX58uW1atUqbd26VfPnz0/2XAcAILW4YoEMlTi86b83lyY+TGzHjh1ycnLSd999J29vb3Xo0EGFChVS9+7d9c4778jLy0s5c+Z86D6WLFmi7du3a8qUKSmq5UE31f67D/AwYWFh8vX1VaNGjZJdXqlSJW3cuFHOzs4aMmSIPvroI/Xp00fLly9/5LZr166tcuXK6auvvtKgQYM0atQoXbt2TVOnTtWKFSus+trY2GjVqlUaNGiQVq9erSFDhujixYtatGiRQkJC0uRYAQBIxBULZKi8efPqjz/+eOTNpaVLl9ahQ4d0+PBh3bhxQ6VKlbJ8KHvuueceuo/XX39dQUFBcnBw0OnTpyX939OJIyIidO/ePeXNm1deXl5ydHR84E21ifUCj7Jjx45H9qldu3aS4X3/Va9evSTDnipXrvxYEwnkzJlT06dP1/Tp01O8DgAAqUGwQIYKDAzUhg0bLDdvJ0ru5lIbGxuVLl3a8vP333+vhISEB34rnCgiIkLh4eEKDw9PsqxSpUoqX768Dhw4IFtbW5UtWzbJTbWStGvXLhUpUoQ5/wEAAB6AoVDIUIkPDvv3zaXSPzei5siRQ/Xq1Ut2vTt37mjkyJHKkyeP1TCq5G52XblyZZJX4k2tX3zxhaZNm2bp27FjR+3Zs8cqXBw7dkw//vij1U21AAAAsMYVC2SoihUrqnfv3vrss88UFxen5557Tj/99JOWLVumYcOGWYYeBQcHK2/evCpVqpSio6P12Wef6a+//tJ3331ndRUhuZtd27Ztm2S/Bw4ckPTPw+98fHws7QMGDNDHH3+sli1baujQobK3t9fUqVPl5+en//3vf+n2ewAAAMjqCBbIcPPmzdMzzzyjBQsWaOXKlSpYsKCmTZumV1991dKncuXKWrBggebPny9nZ2fVqVNH4eHhqZ7z/0Hc3Nz0008/aciQIRo3bpwSEhJUr149TZs2jTn/AQAAHsLGSG5C9KdcdHS0PDw8FBUVJXd39wypoeCHGbLbdHdmcEZXgCeNcxnZSbY9n1+1yegS0h4fbx6KczmLycDz+XE+F3OPBQAAAADTCBYAAAAATCNYAAAAADCNm7cBIDVsGMcLAMC/ccUCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAaN2/jyeKGVwAAgGyJKxYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwLcsFi3Pnzqlbt27y9vaWs7OzypYtq71791qWG4ahd955R3ny5JGzs7MaNWqkEydOZGDFAAAAQPaXpYLFjRs3VKtWLdnb22vt2rU6fPiwpkyZoly5cln6vPfee5oxY4bmzZunXbt2ydXVVU2bNtXdu3czsHIAAAAge8uR0QU8jsmTJ6tAgQJasGCBpa1w4cKWfxuGoenTp+vtt99WmzZtJElffPGF/Pz8tGrVKnXu3DnZ7cbGxio2Ntbyc3R0dDodAQAAAJA9ZakrFqtXr1blypUVFBQkX19fVaxYUR9//LFl+alTp3Tx4kU1atTI0ubh4aFq1appx44dD9zuxIkT5eHhYXkVKFAgXY8DAAAAyG6yVLD466+/NHfuXBUtWlQ//PCD+vfvr0GDBunzzz+XJF28eFGS5OfnZ7Wen5+fZVlyhg0bpqioKMsrIiIi/Q4CAAAAyIay1FCohIQEVa5cWRMmTJAkVaxYUYcOHdK8efPUo0ePVG/X0dFRjo6OaVUmAAAA8NTJUlcs8uTJo1KlSlm1lSxZUn///bckyd/fX5J06dIlqz6XLl2yLAMAAACQ9rJUsKhVq5aOHTtm1Xb8+HEVLFhQ0j83cvv7+2vTpk2W5dHR0dq1a5dq1KjxRGsFAAAAniZZaijUkCFDVLNmTU2YMEHBwcHavXu3PvroI3300UeSJBsbG7366qsaN26cihYtqsKFC2vkyJHKmzev2rZtm7HFAwAAANlYlgoWVapU0cqVKzVs2DCNGTNGhQsX1vTp09W1a1dLnzfeeEO3b99WSEiIIiMjVbt2ba1bt05OTk4ZWDkAAACQvWWpYCFJrVq1UqtWrR643MbGRmPGjNGYMWOeYFUAAADA0y1L3WMBAAAAIHMiWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMe+wnb8fExGjDhg3atm2bDh8+rKtXr8rGxkY+Pj4qWbKkatWqpUaNGsnV1TU96gUAAACQCaX4isXBgwfVs2dP+fv7q127dpo9e7b+/PNP2djYyDAMHT9+XLNmzVK7du3k7++vnj176uDBg+lZOwAAAIBMIkVXLDp16qSvv/5alStX1ujRo9W4cWOVKlVKdnZ2Vv3i4+N1+PBhrV+/XsuXL1fFihUVFBSkr776Kl2KBwAAAJA5pChY2Nraau/evapQocJD+9nZ2als2bIqW7as/ve//+nAgQOaPHlyWtQJAAAAIBNLUbBI7RWHChUqcLUCAAAAeAowKxQAAAAA09IkWHz++edq0qSJSpcurYYNG+qjjz6SYRhpsWkAAAAAWcBjTzf7X2PHjtWcOXPUr18/5c2bV4cPH9arr76qP//8U++9915a1AgAAAAgk0txsDhz5owKFiyYpH3hwoVavHixnnvuOUubv7+/pk6dSrAAAAAAnhIpHgpVqlQpjRw5UjExMVbtbm5uOnPmjFXb33//LTc3t7SpEAAAAECml+Jg8fPPP+vHH39U8eLFFRYWZml/55131LdvXzVo0EDdunVT5cqVNX/+fI0ePTo96gUAAACQCaU4WFSuXFnbtm3TxIkT9dZbb6lGjRras2eP2rdvr99//10NGjSQu7u7Wrdurd9++00vvvhietYNAAAAIBN57Ju3u3Xrpvbt22v8+PGqV6+egoKCNGnSJL399tvpUR8AAACALCBV0826uLho/PjxOnTokKKjo1WsWDFNnDhR9+7dS+v6AAAAAGQBjxUsdu7cqREjRmjIkCFavHixChcurBUrVmjVqlX66quvVKJECa1YsSK9agUAAACQSaU4WHz22WeqXbu2tm/frr///lt9+vRRp06dJEkNGjTQgQMH9NprrykkJEQNGjTQwYMH061oAAAAAJlLioPF+PHjFRoaqs2bN+vrr7/WihUrtHz5cv3111//bMjWVqGhoTpx4oRKliypqlWrplvRAAAAADKXFAeLGzduqGjRopafAwICZBiGIiMjrfrlypVLs2fP1p49e9KsSAAAAACZW4pnhWrevLkmTZokT09PeXp6asqUKSpQoIDKlCmTbP8HtQMAAADIflJ8xWLOnDlq2rSphg4dqq5du8rOzk7fffedHBwc0rM+AAAAAFlAiq9YeHh46JNPPknPWgAAAABkUal6jgUAAAAA/FuKgkW/fv106tSpx974yZMn1a9fv8deDwAAAEDWkqJgERERoeLFi6t58+ZauHChIiIiHtj39OnT+uSTT9SkSROVKFFCZ8+eTbNiAQAAAGROKbrH4vvvv9e2bdv0wQcfKCQkRPHx8fL29lahQoWUK1cuGYahGzdu6NSpU7px44bs7OzUokULbd68WbVr107vYwAAAACQwVJ883atWrVUq1YtXblyRWvWrNGOHTt09OhRyxUJb29vtW/fXjVq1FDLli3l6+ubbkUDAAAAyFxSHCwS5c6dW7169VKvXr3Sox4AAAAAWRCzQgEAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADAtMeebvbfdu7cqc2bN+vy5csaMGCAihYtqpiYGB09elTFihVTzpw506pOAAAAAJlYqq5Y3Lt3T+3bt1etWrU0YsQIzZgxQxEREf9s0NZWTZo00YcffpimhQIAAADIvFIVLEaOHKk1a9Zo7ty5OnbsmAzDsCxzcnJSUFCQvvnmmzQrEgAAAEDmlqpg8dVXX6l///4KCQmRl5dXkuUlS5bUX3/9Zbo4AAAAAFlDqoLF5cuXVbZs2Qcut7OzU0xMTKqLAgAAAJC1pCpYFChQQEePHn3g8m3btunZZ59NdVEAAAAAspZUBYsXXnhB8+fP144dOyxtNjY2kqSPP/5YS5cuVffu3dOmQgAAAACZXqqmmx0xYoR27typunXrqmTJkrKxsdGQIUN0/fp1nT17Vi1atNCQIUPSulYAAAAAmVSqrlg4ODho3bp1WrBggYoUKaISJUooNjZW5cqV08KFC/Xtt9/Kzs4urWsFAAAAkEk99hWLO3fuaMSIEapfv766deumbt26pUddAAAAALKQx75i4ezsrPnz5+vSpUvpUQ8AAACALChVQ6ECAwN16NChtK4FAAAAQBaVqmAxffp0LV68WJ988oni4uLSuiYAAAAAWUyqZoXq2bOnbG1t1a9fPw0aNEj58uWTs7OzVR8bGxv99ttvaVIkAAAAgMwtVcHCy8tL3t7eKl68eFrXAwAAACALSlWw+Omnn9K4DAAAAABZWarusQAAAACAf0vVFQtJio+P16JFi/Tdd9/pzJkzkqSCBQuqVatW6tq1Kw/IAwAAAJ4iqbpiERUVpVq1aql3795av3697t+/r/v372vDhg3q1auXateurejo6LSuFQAAAEAmlapgMWLECO3bt08zZ87UlStX9Ouvv+rXX3/V5cuXNWvWLO3du1cjRoxI61oBAAAAZFKpChYrV67UgAEDNGDAANnb21va7e3t1b9/f/Xv319ff/11mhUJAAAAIHNLVbC4du3aQ6eaLVGihK5fv57qogAAAABkLakKFs8++6xWr179wOWrV69WQEBAqosCAAAAkLWkKlgMGDBA69evV4sWLbR+/XqdPn1ap0+f1g8//KCWLVtqw4YNCg0NTetaAQAAAGRSqZpudsCAAbp8+bImTZqkH374wWqZvb293nnnHfXv3z9NCgQAAACQ+aX6ORajR49WaGioNm7caPUci0aNGsnHxyfNCgQAAACQ+aU6WEiSj4+POnfunFa1AAAAAMiiUnWPxcaNGzV8+PAHLh8xYoR+/PHHVBcFAAAAIGtJVbAYO3asIiIiHrj83LlzGjduXKqLAgAAAJC1pCpYHDx4UNWqVXvg8ipVquj3339PdVEAAAAAspZUBYvY2Fjdu3fvoctjYmJSXRQAAACArCVVwaJMmTJauXJlsssMw9CKFStUqlQpU4UBAAAAyDpSFSxeeeUVbdu2TUFBQTp48KDi4uIUFxen33//XUFBQdqxY4deeeWVtK4VAAAAQCaVqulmu3XrppMnT2rs2LFasWKFbG3/yScJCQmysbHR22+/rR49eqRpoQAAAAAyr1Q/x2LUqFHq1q2bVq5cqb/++kuSFBAQoLZt2yogICDNCgQAAACQ+Zl6QF5AQICGDh2aVrUAAAAAyKJMBYtER48e1bJly3ThwgWVKFFCPXv2lLu7e1psGgAAAEAWkOJgMWvWLM2YMUPbt2+Xj4+Ppf3bb79VUFCQ1fSzM2bM0M6dO636AQAAAMi+Ujwr1OrVqxUQEGAVFuLi4vTSSy/Jzs5OCxYs0MGDBzVp0iSdOXNG48ePT5eCAQAAAGQ+KQ4Whw8fVvXq1a3aNm/erCtXrmjIkCHq0aOHSpcurTfeeEPBwcH6/vvv07xYAAAAAJlTioPFtWvXVKBAAau2TZs2ycbGRu3atbNqr1Wrlv7++++0qRAAAABAppfiYOHn56eLFy9atW3ZskUuLi4qX768VbuDg4McHBzSpkIAAAAAmV6Kg0XlypX1+eef6+bNm5KkP/74Q7t371bTpk2VI4f1PeBHjx5V/vz507ZSAAAAAJlWimeFGjVqlKpUqaKiRYuqdOnS2rdvn2xsbDRs2LAkfVeuXKkGDRqkaaEAAAAAMq8UX7EoW7asfvzxRwUGBur8+fOqXr26vv/+ewUGBlr1++mnn+Ti4qKgoKA0LxYAAABA5vRYD8irWbOmvvvuu4f2qVevng4ePGiqKAAAAABZS4qvWAAAAADAgxAsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaVk6WEyaNEk2NjZ69dVXLW13797VwIED5e3trZw5c6pDhw66dOlSxhUJAAAAPAWybLDYs2eP5s+fr3Llylm1DxkyRN9++62WLVumn3/+WefPn1f79u0zqEoAAADg6ZAlg8WtW7fUtWtXffzxx8qVK5elPSoqSp9++qmmTp2qBg0aKDAwUAsWLND27du1c+fODKwYAAAAyN6yZLAYOHCgWrZsqUaNGlm179u3T/fv37dqL1GihJ555hnt2LHjgduLjY1VdHS01QsAAABAyuXI6AIe1+LFi/Xrr79qz549SZZdvHhRDg4O8vT0tGr38/PTxYsXH7jNiRMn6t13303rUgEAAICnRpa6YhEREaHBgwcrLCxMTk5OabbdYcOGKSoqyvKKiIhIs20DAAAAT4MsFSz27duny5cvq1KlSsqRI4dy5Mihn3/+WTNmzFCOHDnk5+ene/fuKTIy0mq9S5cuyd/f/4HbdXR0lLu7u9ULAAAAQMplqaFQDRs21MGDB63aevXqpRIlSujNN99UgQIFZG9vr02bNqlDhw6SpGPHjunvv/9WjRo1MqJkAAAA4KmQpYKFm5ubypQpY9Xm6uoqb29vS3ufPn302muvycvLS+7u7nrllVdUo0YNVa9ePSNKBgAAAJ4KWSpYpMS0adNka2urDh06KDY2Vk2bNtWcOXMyuiwAAAAgW8vyweKnn36y+tnJyUmzZ8/W7NmzM6YgAAAA4CmUpW7eBgAAAJA5ESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYBrBAgAAAIBpBAsAAAAAphEsAAAAAJhGsAAAAABgGsECAAAAgGlZKlhMnDhRVapUkZubm3x9fdW2bVsdO3bMqs/du3c1cOBAeXt7K2fOnOrQoYMuXbqUQRUDAAAAT4csFSx+/vlnDRw4UDt37tSGDRt0//59NWnSRLdv37b0GTJkiL799lstW7ZMP//8s86fP6/27dtnYNUAAABA9pcjowt4HOvWrbP6eeHChfL19dW+fftUt25dRUVF6dNPP1V4eLgaNGggSVqwYIFKliypnTt3qnr16hlRNgAAAJDtZakrFv8VFRUlSfLy8pIk7du3T/fv31ejRo0sfUqUKKFnnnlGO3bseOB2YmNjFR0dbfUCAAAAkHJZNlgkJCTo1VdfVa1atVSmTBlJ0sWLF+Xg4CBPT0+rvn5+frp48eIDtzVx4kR5eHhYXgUKFEjP0gEAAIBsJ8sGi4EDB+rQoUNavHix6W0NGzZMUVFRlldEREQaVAgAAAA8PbLUPRaJQkNDtWbNGv3yyy/Knz+/pd3f31/37t1TZGSk1VWLS5cuyd/f/4Hbc3R0lKOjY3qWDAAAAGRrWeqKhWEYCg0N1cqVK/Xjjz+qcOHCVssDAwNlb2+vTZs2WdqOHTumv//+WzVq1HjS5QIAAABPjSx1xWLgwIEKDw/XN998Izc3N8t9Ex4eHnJ2dpaHh4f69Omj1157TV5eXnJ3d9crr7yiGjVqMCMUAAAAkI6yVLCYO3euJKlevXpW7QsWLFDPnj0lSdOmTZOtra06dOig2NhYNW3aVHPmzHnClQIAAABPlywVLAzDeGQfJycnzZ49W7Nnz34CFQEAAACQstg9FgAAAAAyJ4IFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADANIIFAAAAANMIFgAAAABMI1gAAAAAMI1gAQAAAMA0ggUAAAAA0wgWAAAAAEwjWAAAAAAwjWABAAAAwDSCBQAAAADTCBYAAAAATCNYAAAAADCNYAEAAADAtGwbLGbPnq1ChQrJyclJ1apV0+7duzO6JAAAACDbypbBYsmSJXrttdc0atQo/frrrypfvryaNm2qy5cvZ3RpAAAAQLaUI6MLSA9Tp05V37591atXL0nSvHnz9N133+mzzz7TW2+9laR/bGysYmNjLT9HRUVJkqKjo59MwclIuJthu05XGfcbTWcZeK5kdpzLWQzn8kNxPmchnMsPxbmcxWTg+Zz4edgwjEf2zXbB4t69e9q3b5+GDRtmabO1tVWjRo20Y8eOZNeZOHGi3n333STtBQoUSLc6n1YeGV1AevHItkeGB8i2/8U5l59K2fK/OufyUynb/lfPBOfzzZs35fGIOrJdsLh69ari4+Pl5+dn1e7n56ejR48mu86wYcP02muvWX5OSEjQ9evX5e3tLRsbm3St92kSHR2tAgUKKCIiQu7u7hldDpBqnMvITjifkV1wLqcPwzB08+ZN5c2b95F9s12wSA1HR0c5OjpatXl6emZMMU8Bd3d3/odHtsC5jOyE8xnZBedy2nvUlYpE2e7mbR8fH9nZ2enSpUtW7ZcuXZK/v38GVQUAAABkb9kuWDg4OCgwMFCbNm2ytCUkJGjTpk2qUaNGBlYGAAAAZF/ZcijUa6+9ph49eqhy5cqqWrWqpk+frtu3b1tmiULGcHR01KhRo5IMOwOyGs5lZCecz8guOJczno2RkrmjsqBZs2bp/fff18WLF1WhQgXNmDFD1apVy+iyAAAAgGwp2wYLAAAAAE9OtrvHAgAAAMCTR7AAAAAAYBrBAgAAAIBpBAsASIWePXuqUKFCj7XOTz/9JBsbG/3000/pUhOQUWxsbDR69GjLzwsXLpSNjY1Onz6dYTUBePIIFk+JOXPmyMbGhpmxkKUlflhJfDk5OalYsWIKDQ1N8lBMIDv577mfI0cO5cuXTz179tS5c+cyujwgyTn679dbb70lSVq/fr369OmjMmXKyM7O7rG/nEHmly2fY4GkwsLCVKhQIe3evVt//vmnnn322YwuCUi1MWPGqHDhwrp79662bt2quXPn6vvvv9ehQ4fk4uLyRGr4+OOPlZCQ8Fjr1K1bV3fu3JGDg0M6VYXs7t/n/s6dO7Vw4UJt3bpVhw4dkpOTU0aXB1jO0X8rU6aMJCk8PFxLlixRpUqVlDdv3owoD+mMYPEUOHXqlLZv364VK1aoX79+CgsL06hRozK6rCRu374tV1fXjC4DWUDz5s1VuXJlSdJLL70kb29vTZ06Vd988426dOmSpH96nFv29vaPvY6trS0f/mDKf899Hx8fTZ48WatXr1ZwcHAGVwdYn6P/NWHCBH388ceyt7dXq1atdOjQoSdcnXl8Vnk4hkI9BcLCwpQrVy61bNlSHTt2VFhYWJI+kZGRGjJkiAoVKiRHR0flz59f3bt319WrVy197t69q9GjR6tYsWJycnJSnjx51L59e508eVLSg8ePnz59WjY2Nlq4cKGlrWfPnsqZM6dOnjypFi1ayM3NTV27dpUkbdmyRUFBQXrmmWfk6OioAgUKaMiQIbpz506Suo8eParg4GDlzp1bzs7OKl68uEaMGCFJ2rx5s2xsbLRy5cok64WHh8vGxkY7dux47N8nMp8GDRpI+idEP+zcSkhI0PTp01W6dGk5OTnJz89P/fr1040bN5Jsc+3atXruuefk5uYmd3d3ValSReHh4Zblyd1jsXjxYgUGBlrWKVu2rD788EPL8gf9P7Js2TIFBgbK2dlZPj4+6tatW5LhLYnHde7cObVt21Y5c+ZU7ty5NXToUMXHx5v59SELq1OnjiRZ3oelf94XO3bsKC8vLzk5Oaly5cpavXp1knUf9b5/7949vfPOOwoMDJSHh4dcXV1Vp04dbd68+ckcHLKdvHnzpupLmUQ3b97Uq6++ajlnfX191bhxY/36669W/Xbt2qUWLVooV65ccnV1Vbly5azeiyXpxx9/VJ06deTq6ipPT0+1adNGR44cseozevRo2djY6PDhw3rhhReUK1cu1a5d27J80aJFlvduLy8vde7cWREREak+vuyAKxZPgbCwMLVv314ODg7q0qWL5s6dqz179qhKlSqSpFu3bqlOnTo6cuSIevfurUqVKunq1atavXq1zp49Kx8fH8XHx6tVq1batGmTOnfurMGDB+vmzZvasGGDDh06pICAgMeuKy4uTk2bNlXt2rX1wQcfWIawLFu2TDExMerfv7+8vb21e/duzZw5U2fPntWyZcss6//++++qU6eO7O3tFRISokKFCunkyZP69ttvNX78eNWrV08FChRQWFiY2rVrl+R3EhAQoBo1apj4zSKzSPxQ5e3tLenB51a/fv20cOFC9erVS4MGDdKpU6c0a9Ys7d+/X9u2bbP8wVu4cKF69+6t0qVLa9iwYfL09NT+/fu1bt06vfDCC8nWsGHDBnXp0kUNGzbU5MmTJUlHjhzRtm3bNHjw4AfWnlhPlSpVNHHiRF26dEkffvihtm3bpv3798vT09PSNz4+Xk2bNlW1atX0wQcfaOPGjZoyZYoCAgLUv39/079HZD2JN0fnypVLkvTHH3+oVq1aypcvn9566y25urpq6dKlatu2rb7++mvLe2FK3vejo6P1ySefqEuXLurbt69u3rypTz/9VE2bNtXu3btVoUKFDDpqZGZRUVFWX0pKko+PT5ps++WXX9by5csVGhqqUqVK6dq1a9q6dauOHDmiSpUqSfrnvbhVq1bKkyePBg8eLH9/fx05ckRr1qyxvBdv3LhRzZs3V5EiRTR69GjduXNHM2fOVK1atfTrr78m+dIoKChIRYsW1YQJE5T4XOnx48dr5MiRCg4O1ksvvaQrV65o5syZqlu3bpL37qeKgWxt7969hiRjw4YNhmEYRkJCgpE/f35j8ODBlj7vvPOOIclYsWJFkvUTEhIMwzCMzz77zJBkTJ069YF9Nm/ebEgyNm/ebLX81KlThiRjwYIFlrYePXoYkoy33noryfZiYmKStE2cONGwsbExzpw5Y2mrW7eu4ebmZtX273oMwzCGDRtmODo6GpGRkZa2y5cvGzly5DBGjRqVZD/I3BYsWGBIMjZu3GhcuXLFiIiIMBYvXmx4e3sbzs7OxtmzZx94bm3ZssWQZISFhVm1r1u3zqo9MjLScHNzM6pVq2bcuXPHqu+/z60ePXoYBQsWtPw8ePBgw93d3YiLi3tg/f/9f+TevXuGr6+vUaZMGat9rVmzxpBkvPPOO1b7k2SMGTPGapsVK1Y0AgMDH/JbQ3aQ3Lm/fPlyI3fu3Iajo6MRERFhGIZhNGzY0Chbtqxx9+5dy7oJCQlGzZo1jaJFi1raUvK+HxcXZ8TGxlotu3HjhuHn52f07t3bql2S1XtqYr2nTp0ye+jIIhL/myf3Sk7Lli2t3kNTwsPDwxg4cOADl8fFxRmFCxc2ChYsaNy4ccNq2b/fvytUqGD4+voa165ds7T99ttvhq2trdG9e3dL26hRowxJRpcuXay2dfr0acPOzs4YP368VfvBgweNHDlyJGl/mjAUKpsLCwuTn5+f6tevL+mfKQE7deqkxYsXW4ZPfP311ypfvnySb/UT+yf28fHx0SuvvPLAPqmR3Leszs7Oln/fvn1bV69eVc2aNWUYhvbv3y9JunLlin755Rf17t1bzzzzzAPr6d69u2JjY7V8+XJL25IlSxQXF6du3bqlum5krEaNGil37twqUKCAOnfurJw5c2rlypXKly+fpc9/z61ly5bJw8NDjRs31tWrVy2vwMBA5cyZ0zK8Y8OGDbp586beeuutJPdDPOxc9/T01O3bt7Vhw4YUH8fevXt1+fJlDRgwwGpfLVu2VIkSJfTdd98lWefll1+2+rlOnTr666+/UrxPZG3/Pvc7duwoV1dXrV69Wvnz59f169f1448/Kjg4WDdv3rSc49euXVPTpk114sQJyxC7lLzv29nZWSYaSEhI0PXr1xUXF6fKlSsnGXoCJJo9e7Y2bNhg9Uornp6e2rVrl86fP5/s8v379+vUqVN69dVXk1wxSDyvL1y4oAMHDqhnz57y8vKyLC9XrpwaN26s77//Psl2//u+u2LFCiUkJCg4ONjq74m/v7+KFi36VA8XZChUNhYfH6/Fixerfv36OnXqlKW9WrVqmjJlijZt2qQmTZro5MmT6tChw0O3dfLkSRUvXlw5cqTdKZMjRw7lz58/Sfvff/+td955R6tXr04y9j0qKkqSLB+kEmeaeJASJUqoSpUqCgsLU58+fST9E7aqV6/OzFhZ2OzZs1WsWDHlyJFDfn5+Kl68uGxt/+97kuTOrRMnTigqKkq+vr7JbvPy5cuS/m9Y1aPOrf8aMGCAli5dqubNmytfvnxq0qSJgoOD1axZsweuc+bMGUlS8eLFkywrUaKEtm7datXm5OSk3LlzW7XlypUr2XtEkD0lnvtRUVH67LPP9Msvv8jR0VGS9Oeff8owDI0cOVIjR45Mdv3Lly8rX758KXrfl6TPP/9cU6ZM0dGjR3X//n1L+39n/QESVa1a9YE3b6dEfHy8rly5YtXm5eUlBwcHvffee+rRo4cKFCigwMBAtWjRQt27d1eRIkUkpez9+2HvuyVLltQPP/yQ5Abt/57vJ06ckGEYKlq0aLL7MHMfSVZHsMjGfvzxR124cEGLFy/W4sWLkywPCwtTkyZN0mx/D/o290E3ljo6Olp9GEzs27hxY12/fl1vvvmmSpQoIVdXV507d049e/Z87Ok9pX+uWgwePFhnz55VbGysdu7cqVmzZj32dpB5POoPV3LnVkJCgnx9fZOdvEBSkg/sj8vX11cHDhzQDz/8oLVr12rt2rVasGCBunfvrs8//9zUthPZ2dmlyXaQdf373G/btq1q166tF154QceOHbO8Pw4dOlRNmzZNdv3H+UJl0aJF6tmzp9q2bavXX39dvr6+srOz08SJE61uFgfSUkRERJIP8ps3b1a9evUUHBysOnXqaOXKlVq/fr3ef/99TZ48WStWrFDz5s3TraZ/j6SQ/vl7YmNjo7Vr1yb7vpwzZ850qyWzI1hkY2FhYfL19dXs2bOTLFuxYoVWrlypefPmKSAg4JFTvgUEBGjXrl26f//+A5N44s2DkZGRVu2J3w6kxMGDB3X8+HF9/vnn6t69u6X9v5dSE7+dSMlUdZ07d9Zrr72mr776Snfu3JG9vb06deqU4pqQPQQEBGjjxo2qVatWkj8S/+0n/XNuPe5VLQcHB7Vu3VqtW7dWQkKCBgwYoPnz52vkyJHJbqtgwYKSpGPHjllmtkp07Ngxy3IgOYkf8uvXr69Zs2apd+/ekv75trRRo0YPXTcl7/vLly9XkSJFtGLFCqsvjjLjdOXIPvz9/ZP8zS9fvrzl33ny5NGAAQM0YMAAXb58WZUqVdL48ePVvHlzq/fvB/0/8O/33f86evSofHx8HjmdbEBAgAzDUOHChVWsWLHHOr7sjnsssqk7d+5oxYoVatWqlTp27JjkFRoaqps3b2r16tXq0KGDfvvtt2SnZTX+/+wHHTp00NWrV5P9pj+xT8GCBWVnZ6dffvnFavmcOXNSXHdi8k/cZuK//ztNXO7cuVW3bl199tln+vvvv5OtJ5GPj4+aN2+uRYsWKSwsTM2aNUuzGSqQdQQHBys+Pl5jx45NsiwuLs4SiJs0aSI3NzdNnDhRd+/eter333Pr365du2b1s62trcqVKydJio2NTXadypUry9fXV/PmzbPqs3btWh05ckQtW7ZM0bHh6VWvXj1VrVpV06dPl7u7u+rVq6f58+frwoULSfr+e3hJSt73k3s/3rVrF9N0I105OTmpUaNGVq9cuXIpPj7eMhw6ka+vr/LmzWt5/6xUqZIKFy6s6dOnJ/mSM/E8zpMnjypUqKDPP//cqs+hQ4e0fv16tWjR4pE1tm/fXnZ2dnr33XeT/F0wDCPJ34OnCVcssqnVq1fr5s2bev7555NdXr16deXOnVthYWEKDw/X8uXLFRQUpN69eyswMFDXr1/X6tWrNW/ePJUvX17du3fXF198oddee027d+9WnTp1dPv2bW3cuFEDBgxQmzZt5OHhoaCgIM2cOVM2NjYKCAjQmjVrLGPXU6JEiRIKCAjQ0KFDde7cObm7u+vrr79Odgz5jBkzVLt2bVWqVEkhISEqXLiwTp8+re+++04HDhyw6tu9e3d17NhRkpL9YIns77nnnlO/fv00ceJEHThwQE2aNJG9vb1OnDihZcuW6cMPP1THjh3l7u6uadOm6aWXXlKVKlUsc5f/9ttviomJeeCwppdeeknXr19XgwYNlD9/fp05c0YzZ85UhQoVVLJkyWTXsbe31+TJk9WrVy8999xz6tKli2W62UKFCmnIkCHp+StBNvH6668rKChICxcu1OzZs1W7dm2VLVtWffv2VZEiRXTp0iXt2LFDZ8+e1W+//WZZ51Hv+61atdKKFSvUrl07tWzZUqdOndK8efNUqlQp3bp1K4OPGlnR77//bnmmyp9//qmoqCiNGzdO0j9XJVq3bv3AdW/evKn8+fOrY8eOKl++vHLmzKmNGzdqz549mjJliqR/vtCZO3euWrdurQoVKqhXr17KkyePjh49qj/++EM//PCDJOn9999X8+bNVaNGDfXp08cy3ayHh4dGjx79yOMICAjQuHHjNGzYMJ0+fVpt27aVm5ubTp06pZUrVyokJERDhw41+dvKojJgJio8Aa1btzacnJyM27dvP7BPz549DXt7e+Pq1avGtWvXjNDQUCNfvnyGg4ODkT9/fqNHjx7G1atXLf1jYmKMESNGGIULFzbs7e0Nf39/o2PHjsbJkyctfa5cuWJ06NDBcHFxMXLlymX069fPOHToULLTzbq6uiZb1+HDh41GjRoZOXPmNHx8fIy+ffsav/32W5JtGIZhHDp0yGjXrp3h6elpODk5GcWLFzdGjhyZZJuxsbFGrly5DA8PjyRTiCLrSJzOcM+ePQ/s87BzyzAM46OPPjICAwMNZ2dnw83NzShbtqzxxhtvGOfPn7fqt3r1aqNmzZqGs7Oz4e7ublStWtX46quvrPbz76kSly9fbjRp0sTw9fU1HBwcjGeeecbo16+fceHCBUufB03JvGTJEqNixYqGo6Oj4eXlZXTt2tU4e/Zsio4rcTpEZG8PO/fj4+ONgIAAIyAgwIiLizNOnjxpdO/e3fD39zfs7e2NfPnyGa1atTKWL19utd6j3vcTEhKMCRMmGAULFjQcHR2NihUrGmvWrEly7hsG080iZe/PD5uStkePHg/dfmxsrPH6668b5cuXN9zc3AxXV1ejfPnyxpw5c5L03bp1q9G4cWNLv3LlyhkzZ8606rNx40ajVq1alvf41q1bG4cPH7bqk/j+euXKlWRr+vrrr43atWsbrq6uhqurq1GiRAlj4MCBxrFjxx56LNmZjWE85No+kE3ExcUpb968at26tT799NOMLgcAACDb4R4LPBVWrVqlK1euWN0QDgAAgLTDFQtka7t27dLvv/+usWPHysfHh4c6AQAApBOuWCBbmzt3rvr37y9fX1998cUXGV0OAABAtsUVCwAAAACmccUCAAAAgGkECwAAAACmESwAAAAAmEawAAAAAGAawQIAAACAaQQLAAAAAKYRLAAAAACYRrAAAAAAYNr/AwVO52+u2/4bAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_2019_vs_2024()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
