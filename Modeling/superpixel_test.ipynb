{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "scripts_path = Path(\"../Data-Preprocessing/\").resolve()\n",
    "sys.path.append(str(scripts_path))\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from scripts.data_visualiser import *\n",
    "from scripts.data_loader import *\n",
    "from scripts.data_preprocessor import *\n",
    "from scripts.temporal_data_preprocessor import *\n",
    "from scripts.temporal_data_loader import *\n",
    "from scripts.temporal_visualiser import *\n",
    "from scripts.temporal_chanel_refinement import *\n",
    "from model_scripts.get_statistics import *\n",
    "from model_scripts.dataset_creation import *\n",
    "from model_scripts.train_model_ae import *\n",
    "from model_scripts.model_visualiser import *\n",
    "from model_scripts.superpixel import *\n",
    "from Pipeline.pre_processing_pipeline import *\n",
    "from Pipeline.temporal_preprocessing_pipeline import *\n",
    "from model_scripts.pre_trained_extraction import *\n",
    "import numpy as np\n",
    "import preprocessing_config as config\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import skimage.measure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_pipeline = PreProcessingPipelineTemporal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fn, dataloader_train = temp_pipeline.get_processed_trainloader(64, 'indexbands', vi_type='msi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2425, (64, 64, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_images = load_field_images_temporal(config.base_directory_temporal_train1)\n",
    "border_removed_images_train = blacken_field_borders_temporal(temporal_images)\n",
    "field_numbers_train, indices_images_train = multiple_indices_temporal_cubes(border_removed_images_train)\n",
    "\n",
    "len(indices_images_train), indices_images_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, (64, 64, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_images_test = load_field_images_temporal(config.base_directory_temporal_test1)\n",
    "border_removed_images = blacken_field_borders_temporal(temporal_images_test)\n",
    "field_numbers_test, indices_images_test = multiple_indices_temporal_cubes(border_removed_images)\n",
    "\n",
    "(len(indices_images_test), indices_images_test[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2425, 7, 64, 64, 3), (48, 7, 64, 64, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor_train = np.stack(indices_images_train)  # Shape: (N x 7 x 64 x 64 x 6)\n",
    "image_tensor_test = np.stack(indices_images_test)   # Shape: (N x 7 x 64 x 64 x 6)\n",
    "\n",
    "image_tensor_train.shape, image_tensor_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super-patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2425, 7, 3, 64, 64]), torch.Size([48, 7, 3, 64, 64]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor_train = torch.tensor(image_tensor_train, dtype=torch.float32).permute(0, 1, 4, 2, 3)  # (N, T, H, W, C) -> (N, T, C, H, W)\n",
    "image_tensor_test = torch.tensor(image_tensor_test, dtype=torch.float32).permute(0, 1, 4, 2, 3)  # (N, T, H, W, C) -> (N, T, C, H, W)\n",
    "image_tensor_train.shape, image_tensor_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches, train_patch_coordinates = non_overlapping_sliding_window(image_tensor_train, field_numbers_train, patch_size=4)\n",
    "test_patches, test_patch_coordinates = non_overlapping_sliding_window(image_tensor_test, field_numbers_test, patch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1197, torch.Size([7, 3, 4, 4]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_patches), test_patches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_temporal_stack_rgb(border_removed_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_single_patch_temporal_rgb(test_patches[2], test_patch_coordinates[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patch_coordinates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_patches(image_tensor_test, field_numbers_test, test_patch_coordinates, 0, patch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders - for Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches = torch.stack(train_patches)\n",
    "test_patches = torch.stack(test_patches)\n",
    "test_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloader_train = create_data_loader(train_patches, train_patch_coordinates, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch_inputs, batch_field_numbers in dataloader_train:\n",
    "    print(\"Batch Inputs Shape:\", batch_inputs.shape) \n",
    "    print(\"Batch Field Numbers:\", batch_field_numbers)\n",
    "    break  # Show one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloader_test = create_data_loader(test_patches, test_patch_coordinates, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for batch_inputs, batch_field_numbers in dataloader_test:\n",
    "    print(\"Batch Inputs Shape:\", batch_inputs.shape) \n",
    "    print(\"Batch Field Numbers:\", batch_field_numbers)\n",
    "    break  # Show one batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches_tensor = torch.stack(train_patches)  # Convert to tensor [N, T, C, H, W]\n",
    "test_patches_tensor = torch.stack(test_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhumikasadbhave007/tensorflow-test/env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "kmeans = train_kmeans_patches(train_patches_tensor, n_clusters=2, random_state=96)\n",
    "\n",
    "train_patch_predictions = kmeans.predict(train_patches_tensor.reshape(train_patches_tensor.size(0), -1).numpy())\n",
    "test_patch_predictions = kmeans.predict(test_patches_tensor.reshape(test_patches_tensor.size(0), -1).numpy())\n",
    "\n",
    "# Assign field labels\n",
    "threshold = config.patch_to_field_threshold\n",
    "train_field_labels = assign_field_labels(train_patch_coordinates, train_patch_predictions, threshold)\n",
    "test_field_labels = assign_field_labels(test_patch_coordinates, test_patch_predictions, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5409836065573771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.38      0.42        26\n",
      "           1       0.59      0.66      0.62        35\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.52      0.52      0.52        61\n",
      "weighted avg       0.53      0.54      0.53        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report = evaluate_test_labels(test_field_labels, config.labels_path)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save train predictions to Excel\n",
    "# save_train_predictions_to_excel(train_field_labels, \"train_predictions.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Models + k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches_tensor = torch.stack(train_patches) \n",
    "test_patches_tensor = torch.stack(test_patches)\n",
    "train_patches_tensor.shape, test_patches_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpatioTemporalFeatureExtractor(\n",
    "    spatial_weights=ResNet18_Weights.SENTINEL2_ALL_MOCO,\n",
    "    input_channels=10,\n",
    ")\n",
    "\n",
    "train_features = model(train_patches_tensor)\n",
    "print(train_features.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
