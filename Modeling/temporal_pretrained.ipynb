{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "sys.path.append('/home/k64835/Master-Thesis-SITS')\n",
    "\n",
    "scripts_path = Path(\"../Data-Preprocessing/\").resolve()\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "scripts_path = Path(\"../Evaluation/\").resolve()\n",
    "sys.path.append(str(scripts_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from scripts.data_visualiser import *\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scripts.data_loader import *\n",
    "from scripts.data_preprocessor import *\n",
    "from scripts.temporal_data_preprocessor import *\n",
    "from scripts.temporal_data_loader import *\n",
    "from scripts.temporal_visualiser import *\n",
    "from scripts.temporal_chanel_refinement import *\n",
    "from model_scripts.model_helper import *\n",
    "from model_scripts.pretrained_temporal_feature_extraction import *\n",
    "from model_scripts.dataset_creation import *\n",
    "from model_scripts.train_model_ae import *\n",
    "from model_scripts.model_visualiser import *\n",
    "from evaluation_scripts.patch_evaluation_helper import get_clustering_accuracy\n",
    "from model_scripts.clustering import *\n",
    "from model_scripts.subpatch_extraction import *\n",
    "from evaluation_scripts.result_visualiser import *\n",
    "from evaluation_scripts.evaluation_helper import *\n",
    "from Pipeline.temporal_preprocessing_pipeline import *\n",
    "import numpy as np\n",
    "import config\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import skimage.measure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model 1: Resnet 3D trained on Video Data (Temporal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset prep: RGB\n",
    "\n",
    "Data: Extracted and Pre-processed Patches (each patch containing a sugarbeet field)\n",
    "\n",
    "Dimensions: (N, T, C, H, W) = (N, 7, 10, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2425, 7, 3, 64, 64]), torch.Size([48, 7, 3, 64, 64]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline = PreProcessingPipelineTemporal()\n",
    "field_numbers_train, acquisition_dates_train, patch_tensor_train, images_visualisation_train = preprocessing_pipeline.get_processed_temporal_cubes('train', 'rgb')\n",
    "field_numbers_eval, acquisition_dates_eval, patch_tensor_eval, images_visualisation_eval = preprocessing_pipeline.get_processed_temporal_cubes('eval', 'rgb')\n",
    "patch_tensor_train.shape, patch_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Patch-level Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = create_data_loader(patch_tensor_train, field_numbers_train, batch_size=config.ae_batch_size, shuffle=True)\n",
    "dataloader_eval = create_data_loader(patch_tensor_eval, field_numbers_eval, batch_size=config.ae_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet3D Extracted Features size: 512\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "resnet3D_extractor = ResNet3DFeatureExtractor()\n",
    "\n",
    "tf_features_train, train_coord_dl = extract_features(resnet3D_extractor, dataloader_train, device)\n",
    "tf_features_eval, eval_coord_dl = extract_features(resnet3D_extractor, dataloader_eval, device)\n",
    "\n",
    "print(\"ResNet3D Extracted Features size:\", tf_features_train.shape[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = kmeans_function(tf_features_train.cpu(), n_clusters=2, random_state=11)\n",
    "\n",
    "train_patch_predictions = kmeans.predict(tf_features_train.reshape(tf_features_train.size(0), -1).numpy().astype(np.float32))\n",
    "eval_patch_predictions = kmeans.predict(tf_features_eval.reshape(tf_features_eval.size(0), -1).numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure all predictions are not zeros/ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(eval_patch_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Accuracy: Convert sub-patch level labels to patch-level labels and compare with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease cluster: 1\n",
      "Accuracy: 42.62\n",
      "Precision: 50.0\n",
      "Recall: 62.86\n",
      "F1-score: 55.7\n",
      "F2-score: 59.78\n"
     ]
    }
   ],
   "source": [
    "disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics_patch_level(field_numbers_eval, eval_patch_predictions, config.labels_path)\n",
    "print(\"Disease cluster:\", disease)\n",
    "print(\"Accuracy:\",acc)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1-score:\",f1_score)\n",
    "print(\"F2-score:\", f2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(config.resnet3D_path, 'wb') as file:\n",
    "#     pickle.dump(kmeans, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model 2: Resnet trained on Sentinel-2 (Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset prep: B10 \n",
    "Use patch level images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2425, 7, 10, 64, 64]), torch.Size([48, 7, 10, 64, 64]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessing_pipeline = PreProcessingPipelineTemporal()\n",
    "field_numbers_train, acquisition_dates_train, patch_tensor_train, visualisation_train = preprocessing_pipeline.get_processed_temporal_cubes('train', 'b10')\n",
    "field_numbers_eval, acquisition_dates_eval, patch_tensor_eval, visualisation_eval = preprocessing_pipeline.get_processed_temporal_cubes('eval', 'b10')\n",
    "patch_tensor_train.shape, patch_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Last Timestep images since this model requires non-temporal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 10, 64, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_last_timestep_patches = get_last_timestep_patches(patch_tensor_train)\n",
    "test_last_timestep_patches = get_last_timestep_patches(patch_tensor_eval)\n",
    "\n",
    "test_last_timestep_patches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Patch-level Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = create_data_loader(train_last_timestep_patches, field_numbers_train, batch_size=config.batch_size, shuffle=True)\n",
    "dataloader_eval = create_data_loader(test_last_timestep_patches, field_numbers_eval, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 10, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "for ip,_ in dataloader_eval:\n",
    "    print(ip.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet 18 (trained on Sentinel-2 images) Extracted Features Shape: 512\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "time_steps = 7\n",
    "in_channels = 10\n",
    "sentinel2_resnet_extractor = SpectralSentinel2FeatureExtractor(in_channels)\n",
    "\n",
    "tf_features_train, train_coord_dl = extract_features(sentinel2_resnet_extractor, dataloader_train, device)\n",
    "tf_features_eval, eval_coord_dl = extract_features(sentinel2_resnet_extractor, dataloader_eval, device)\n",
    "\n",
    "print(\"Resnet 18 (trained on Sentinel-2 images) Extracted Features Shape:\", tf_features_train.shape[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = kmeans_function(tf_features_train.cpu(), n_clusters=2, random_state=13)\n",
    "\n",
    "train_patch_predictions = kmeans.predict(tf_features_train.reshape(tf_features_train.size(0), -1).numpy().astype(np.float32))\n",
    "eval_patch_predictions = kmeans.predict(tf_features_eval.reshape(tf_features_eval.size(0), -1).numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure all predictions are not zeros/ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.unique(eval_patch_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Accuracy: Convert sub-patch level labels to patch-level labels and compare with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease cluster: 0\n",
      "Accuracy: 55.74\n",
      "Precision: 60.53\n",
      "Recall: 65.71\n",
      "F1-score: 63.01\n",
      "F2-score: 64.61\n"
     ]
    }
   ],
   "source": [
    "disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics_patch_level(field_numbers_eval, eval_patch_predictions, config.labels_path)\n",
    "print(\"Disease cluster:\", disease)\n",
    "print(\"Accuracy:\",acc)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1-score:\",f1_score)\n",
    "print(\"F2-score:\", f2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(config.resent_sentinel_path, 'wb') as file:\n",
    "#     pickle.dump(kmeans, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model 3: ViT pre-trained on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset prep: RGB Images\n",
    "\n",
    "Use patch-level images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2425, 7, 3, 64, 64]), torch.Size([48, 7, 3, 64, 64]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline = PreProcessingPipelineTemporal()\n",
    "field_numbers_train, acquisition_dates_train, patch_tensor_train, visualisation_train = preprocessing_pipeline.get_processed_temporal_cubes('train', 'rgb')\n",
    "field_numbers_eval, acquisition_dates_eval, patch_tensor_eval, visualisation_eval = preprocessing_pipeline.get_processed_temporal_cubes('eval', 'rgb')\n",
    "patch_tensor_train.shape, patch_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2425, 7, 3, 224, 224]), torch.Size([48, 7, 3, 224, 224]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_tensor_train = resize_images_transfer_learning(patch_tensor_train, (224, 224))\n",
    "resized_tensor_eval = resize_images_transfer_learning(patch_tensor_eval, (224, 224))\n",
    "resized_tensor_train.shape, resized_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Patch-level Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = create_data_loader(resized_tensor_train, field_numbers_train, batch_size=config.batch_size, shuffle=True)\n",
    "dataloader_eval = create_data_loader(resized_tensor_eval, field_numbers_eval, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision Transformer (trained on imagenet) Extracted Features Shape: 768\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "vit_extractor = VisionTransformerExtractor()\n",
    "\n",
    "tf_features_train, train_coord_dl = extract_features(vit_extractor, dataloader_train, device)\n",
    "tf_features_eval, eval_coord_dl = extract_features(vit_extractor, dataloader_eval, device)\n",
    "\n",
    "print(\"Vision Transformer (trained on imagenet) Extracted Features Shape:\", tf_features_train.shape[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = kmeans_function(tf_features_train.cpu(), n_clusters=2, random_state=14)\n",
    "\n",
    "train_patch_predictions = kmeans.predict(tf_features_train.reshape(tf_features_train.size(0), -1).numpy().astype(np.float32))\n",
    "eval_patch_predictions = kmeans.predict(tf_features_eval.reshape(tf_features_eval.size(0), -1).numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure all predictions are not zeros/ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(eval_patch_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Accuracy: Convert sub-patch level labels to patch-level labels and compare with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease cluster: 1\n",
      "Accuracy: 52.46\n",
      "Precision: 57.14\n",
      "Recall: 68.57\n",
      "F1-score: 62.34\n",
      "F2-score: 65.93\n"
     ]
    }
   ],
   "source": [
    "disease, acc, precision, recall, f1_score, f2_score = evaluate_clustering_metrics_patch_level(field_numbers_eval, eval_patch_predictions, config.labels_path)\n",
    "print(\"Disease cluster:\", disease)\n",
    "print(\"Accuracy:\",acc)\n",
    "print(\"Precision:\",precision)\n",
    "print(\"Recall:\",recall)\n",
    "print(\"F1-score:\",f1_score)\n",
    "print(\"F2-score:\", f2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(config.vit_imagenet_path, 'wb') as file:\n",
    "#     pickle.dump(kmeans, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
