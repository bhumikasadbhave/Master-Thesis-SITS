{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "scripts_path = Path(\"../Data-Preprocessing/\").resolve()\n",
    "sys.path.append(str(scripts_path))\n",
    "\n",
    "scripts_path = Path(\"../Evaluation/\").resolve()\n",
    "sys.path.append(str(scripts_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from scripts.data_visualiser import *\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Modeling.model_scripts.subpatch_extraction import *\n",
    "from scripts.data_loader import *\n",
    "from scripts.data_preprocessor import *\n",
    "from scripts.temporal_data_preprocessor import *\n",
    "from scripts.temporal_data_loader import *\n",
    "from scripts.temporal_visualiser import *\n",
    "from scripts.temporal_chanel_refinement import *\n",
    "from model_scripts.get_statistics import *\n",
    "from model_scripts.pre_trained_temporal import *\n",
    "from model_scripts.dataset_creation import *\n",
    "from model_scripts.train_model_ae import *\n",
    "from model_scripts.model_visualiser import *\n",
    "from model_scripts.clustering import *\n",
    "from evaluation_scripts.result_visualiser import *\n",
    "from evaluation_scripts.label_helper import *\n",
    "from Pipeline.pre_processing_pipeline import *\n",
    "from Pipeline.temporal_preprocessing_pipeline import *\n",
    "import numpy as np\n",
    "import preprocessing_config as config\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "import skimage.measure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_pipeline = PreProcessingPipelineTemporal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fn, dataloader_train = temp_pipeline.get_processed_trainloader(64, 'indexbands', vi_type='msi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2425, (64, 64, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_images = load_field_images_temporal(config.base_directory_temporal_train1)\n",
    "border_removed_images_train = blacken_field_borders_temporal(temporal_images)\n",
    "field_numbers_train, indices_images_train = allbands_temporal_cubes(border_removed_images_train)\n",
    "\n",
    "len(indices_images_train), indices_images_train[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, (64, 64, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_images_eval = load_field_images_temporal(config.base_directory_temporal_test1)\n",
    "border_removed_images = blacken_field_borders_temporal(temporal_images_eval)\n",
    "field_numbers_eval, indices_images_eval = allbands_temporal_cubes(border_removed_images)\n",
    "\n",
    "(len(indices_images_eval), indices_images_eval[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2425, 7, 64, 64, 10), (48, 7, 64, 64, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor_train = np.stack(indices_images_train)  # Shape: (N x 7 x 64 x 64 x 6)\n",
    "image_tensor_eval = np.stack(indices_images_eval)   # Shape: (N x 7 x 64 x 64 x 6)\n",
    "\n",
    "image_tensor_train.shape, image_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2425, 7, 10, 64, 64]), torch.Size([48, 7, 10, 64, 64]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensor_train = torch.tensor(image_tensor_train, dtype=torch.float32).permute(0, 1, 4, 2, 3)  # (N, T, H, W, C) -> (N, T, C, H, W)\n",
    "image_tensor_eval = torch.tensor(image_tensor_eval, dtype=torch.float32).permute(0, 1, 4, 2, 3)  # (N, T, H, W, C) -> (N, T, C, H, W)\n",
    "image_tensor_train.shape, image_tensor_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(867, torch.Size([7, 10, 5, 5]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_patches, train_patch_coordinates = non_overlapping_sliding_window(image_tensor_train, field_numbers_train, patch_size=5)\n",
    "eval_patches, eval_patch_coordinates = non_overlapping_sliding_window(image_tensor_eval, field_numbers_eval, patch_size=5)\n",
    "len(eval_patches), eval_patches[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39042, 39042)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_patches), len(train_patch_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches = np.stack(train_patches)  # Shape: (N x 7 x 6 x 5 x 5)\n",
    "eval_patches = np.stack(eval_patches)   # Shape: (N x 7 x 6 x 5 x 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1167134.0', 25, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_patch_coordinates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1167134.0_25_25'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_coord_dataloader = field_nos_dataloader(train_patch_coordinates)\n",
    "eval_coord_dataloader = field_nos_dataloader(eval_patch_coordinates)\n",
    "train_coord_dataloader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39042"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_coord_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch Inputs Shape: torch.Size([64, 10, 7, 5, 5])\n",
      "Train Batch Field Numbers: ('1222816.0_25_30', '1175368.0_35_10', '1223522.0_1223526.0_1223533.0_20_15', '1222460.0_1222465.0_1229355.0_30_15', '1228883.0_25_45', '1187379.0_25_30', '1224172.0_30_35', '1196307.0_1218729.0_1218733.0_1218746.0_1223915.0_40_35', '1223509.0_25_50', '1219440.0_1219441.0_1219442.0_1219443.0_1219444.0_45_45', '1219886.0_1219889.0_50_20', '1187577.0_25_25', '1225347.0_40_15', '1176302.0_1176303.0_1193921.0_1195992.0_30_25', '1218979.0_30_25', '1223174.0_1223178.0_25_45', '1187375.0_1226275.0_45_40', '1225197.0_30_25', '1222258.0_1222259.0_1228169.0_30_30', '1226145.0_30_45', '1185910.0_1228312.0_1228611.0_15_50', '1223690.0_1229444.0_25_30', '1226165.0_25_30', '1219845.0_1224190.0_25_45', '1224345.0_30_30', '1222370.0_25_25', '1216702.0_1216710.0_1216716.0_1216720.0_35_30', '1222237.0_1222240.0_1223306.0_30_50', '1175685.0_1175686.0_40_15', '1195751.0_30_30', '1226150.0_1226372.0_25_30', '1168695.0_1220328.0_25_20', '1219697.0_15_40', '1228228.0_25_35', '1222241.0_20_25', '1178712.0_35_25', '1224917.0_1228543.0_20_20', '1223647.0_40_25', '1215718.0_30_25', '1167998.0_25_20', '1182099.0_1182100.0_1194613.0_1194616.0_1227448.0_35_30', '1173847.0_30_20', '1185903.0_30_35', '1195867.0_1218138.0_1222128.0_1222135.0_1222222.0_40_50', '1218822.0_1228540.0_30_25', '1177436.0_35_30', '1227972.0_1227975.0_1228168.0_45_35', '1223633.0_1223634.0_15_45', '1167196.0_1226039.0_25_25', '1169477.0_1174791.0_20_25', '1223485.0_1223490.0_1227669.0_15_25', '1220522.0_1220523.0_30_50', '1169561.0_1196299.0_40_45', '1170626.0_1170629.0_25_30', '1226386.0_35_25', '1224983.0_25_35', '1175675.0_35_35', '1182099.0_1194613.0_1194616.0_1194618.0_5_40', '1216570.0_1216574.0_35_15', '1194635.0_30_20', '1194744.0_30_25', '1194482.0_1194484.0_1226394.0_35_20', '1195716.0_1195721.0_35_25', '1229755.0_20_25')\n",
      "Test Batch Inputs Shape: torch.Size([64, 10, 7, 5, 5])\n",
      "Test Batch Field Numbers: ('1222547.0_20_30', '1218303.0_15_25', '1218972.0_25_30', '1222791.0_30_35', '1223501.0_35_20', '1227490.0_30_30', '1189799.0_30_30', '1225455.0_35_25', '1234575.0_25_30', '1182955.0_25_25', '1182767.0_35_25', '1225950.0_1225952.0_1225956.0_30_20', '1187685.0_1187687.0_1187688.0_35_30', '1223879.0_30_40', '1179716.0_1222830.0_50_30', '1179923.0_1179924.0_1179925.0_1179927.0_1179929.0_1179930.0_25_25', '1223364.0_30_35', '1224912.0_30_25', '1221124.0_25_35', '1227580.0_35_10', '1180792.0_1185840.0_1216711.0_1225856.0_1228645.0_35_35', '1225437.0_25_25', '1220331.0_45_35', '1187038.0_1187039.0_25_25', '1224261.0_35_30', '1181153.0_30_25', '1179885.0_1220122.0_35_35', '1167963.0_1167964.0_20_20', '1227002.0_1227650.0_25_15', '1183110.0_30_20', '1225243.0_25_35', '1225108.0_1229489.0_30_15', '1216281.0_30_35', '1223790.0_20_35', '1228229.0_30_30', '1187077.0_1221746.0_40_30', '1216095.0_15_40', '1170134.0_1224012.0_30_30', '1224349.0_30_40', '1219697.0_25_30', '1224087.0_30_30', '1228339.0_25_30', '1168522.0_35_25', '1189641.0_35_30', '1228883.0_35_30', '1222361.0_30_25', '1168695.0_1220328.0_35_20', '1217039.0_1220329.0_20_30', '1180888.0_1180895.0_20_20', '1220365.0_1220367.0_1220369.0_20_25', '1169843.0_1169844.0_40_35', '1219894.0_30_5', '1191581.0_1224139.0_1224143.0_45_20', '1225870.0_1228623.0_20_20', '1224396.0_30_25', '1194297.0_1194299.0_1194300.0_1194301.0_1217493.0_20_45', '1217784.0_35_25', '1177284.0_1177318.0_1177321.0_1177520.0_1182096.0_1217803.0_20_30', '1189809.0_1226018.0_1228344.0_1228346.0_1228347.0_20_15', '1172752.0_1172753.0_1227428.0_45_40', '1172260.0_1218252.0_35_35', '1223220.0_1225758.0_1225764.0_40_10', '1177211.0_1183102.0_30_30', '1167541.0_1228263.0_50_10')\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8  \n",
    "\n",
    "# Split patches and corresponding field numbers\n",
    "train_patches, test_patches, train_field_numbers, test_field_numbers = train_test_split(\n",
    "    train_patches, train_coord_dataloader, test_size=1-train_ratio, random_state=42\n",
    ")\n",
    "\n",
    "# Create train and test dataloaders\n",
    "batch_size = 64\n",
    "dataloader_train = create_data_loader(train_patches, train_field_numbers, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = create_data_loader(test_patches, test_field_numbers, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for batch_inputs, batch_field_numbers in dataloader_train:\n",
    "    print(\"Train Batch Inputs Shape:\", batch_inputs.shape)\n",
    "    print(\"Train Batch Field Numbers:\", batch_field_numbers)\n",
    "    break  \n",
    "\n",
    "for batch_inputs, batch_field_numbers in dataloader_test:\n",
    "    print(\"Test Batch Inputs Shape:\", batch_inputs.shape)\n",
    "    print(\"Test Batch Field Numbers:\", batch_field_numbers)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Batch Inputs Shape: torch.Size([64, 10, 7, 5, 5])\n",
      "Eval Batch Field Numbers: ('1168039.0_20_25', '1168039.0_20_30', '1168039.0_20_35', '1168039.0_25_25', '1168039.0_25_30', '1168039.0_25_35', '1168039.0_30_25', '1168039.0_30_30', '1168039.0_30_35', '1168039.0_35_25', '1168039.0_35_30', '1168039.0_35_35', '1228889.0_25_15', '1228889.0_25_20', '1228889.0_25_25', '1228889.0_25_30', '1228889.0_25_35', '1228889.0_25_40', '1228889.0_30_15', '1228889.0_30_20', '1228889.0_30_25', '1228889.0_30_30', '1228889.0_30_35', '1228889.0_30_40', '1228889.0_35_15', '1228889.0_35_20', '1228889.0_35_25', '1228889.0_35_30', '1168663.0_1176271.0_25_35', '1168663.0_1176271.0_25_40', '1168663.0_1176271.0_30_20', '1168663.0_1176271.0_30_25', '1168663.0_1176271.0_30_30', '1168663.0_1176271.0_30_35', '1168663.0_1176271.0_30_40', '1168663.0_1176271.0_35_20', '1168663.0_1176271.0_35_25', '1168663.0_1176271.0_35_30', '1168663.0_1176271.0_35_35', '1168663.0_1176271.0_35_40', '1168692.0_1220431.0_15_20', '1168692.0_1220431.0_15_25', '1168692.0_1220431.0_15_30', '1168692.0_1220431.0_20_15', '1168692.0_1220431.0_20_20', '1168692.0_1220431.0_20_25', '1168692.0_1220431.0_20_30', '1168692.0_1220431.0_20_35', '1168692.0_1220431.0_25_15', '1168692.0_1220431.0_25_20', '1168692.0_1220431.0_25_25', '1168692.0_1220431.0_25_30', '1168692.0_1220431.0_25_35', '1168692.0_1220431.0_30_20', '1168692.0_1220431.0_30_25', '1168692.0_1220431.0_30_30', '1168692.0_1220431.0_30_35', '1168692.0_1220431.0_30_40', '1168692.0_1220431.0_35_30', '1168692.0_1220431.0_35_35', '1168692.0_1220431.0_35_40', '1168692.0_1220431.0_40_35', '1168692.0_1220431.0_40_40', '1168692.0_1220431.0_45_35')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataloader_eval = create_data_loader(eval_patches, eval_coord_dataloader, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for batch_inputs, batch_field_numbers in dataloader_eval:\n",
    "    print(\"Eval Batch Inputs Shape:\", batch_inputs.shape) \n",
    "    print(\"Eval Batch Field Numbers:\", batch_field_numbers)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained Models: Resnet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31233, 7, 10, 5, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "train_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet3D Extracted Features Shape: torch.Size([31233, 512])\n"
     ]
    }
   ],
   "source": [
    "resnet3d_extractor = ResNet3DFeatureExtractor()\n",
    "resnet3d_features_train, train_coord_dl = extract_features(resnet3d_extractor, dataloader_train, device)\n",
    "print(\"ResNet3D Extracted Features Shape:\", resnet3d_features_train.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet3D Extracted Features Shape: torch.Size([7809, 512])\n"
     ]
    }
   ],
   "source": [
    "resnet3d_features_test, test_coord_dl = extract_features(resnet3d_extractor, dataloader_test, device)\n",
    "print(\"ResNet3D Extracted Features Shape:\", resnet3d_features_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet3D Extracted Features Shape: torch.Size([867, 512])\n"
     ]
    }
   ],
   "source": [
    "resnet3d_features_eval, eval_coord_dl = extract_features(resnet3d_extractor, dataloader_eval, device)\n",
    "print(\"ResNet3D Extracted Features Shape:\", resnet3d_features_eval.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k64835/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "kmeans = train_kmeans_patches(resnet3d_features_train.cpu(), n_clusters=2, random_state=12)\n",
    "\n",
    "train_patch_predictions = kmeans.predict(resnet3d_features_train.reshape(resnet3d_features_train.size(0), -1).numpy().astype(np.float32))\n",
    "test_patch_predictions = kmeans.predict(resnet3d_features_test.reshape(resnet3d_features_test.size(0), -1).numpy().astype(np.float32))\n",
    "eval_patch_predictions = kmeans.predict(resnet3d_features_eval.reshape(resnet3d_features_eval.size(0), -1).numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign field labels\n",
    "threshold = 0.5\n",
    "train_field_labels = assign_field_labels_ae(train_coord_dl, train_patch_predictions, threshold)\n",
    "test_field_labels = assign_field_labels_ae(test_coord_dl, test_patch_predictions, threshold)\n",
    "eval_field_labels = assign_field_labels_ae(eval_coord_dl, eval_patch_predictions, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5245901639344263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.23      0.29        26\n",
      "           1       0.57      0.74      0.64        35\n",
      "\n",
      "    accuracy                           0.52        61\n",
      "   macro avg       0.48      0.49      0.47        61\n",
      "weighted avg       0.49      0.52      0.49        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, report, x_y_coords = evaluate_test_labels_ae(eval_field_labels, config.labels_path)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
